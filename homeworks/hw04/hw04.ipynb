{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb281ed",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw04.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85472a10",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "\n",
    "#### Homework 4\n",
    "\n",
    "# Exploratory Data Analysis and Missing Values\n",
    "\n",
    "### EECS 398-003: Practical Data Science, Fall 2024\n",
    "\n",
    "#### Due Thursday, September 26th at 11:59PM\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085b6e81",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to Homework 4! In this homework, you will practice exploratory data analysis. That is, you'll learn how to take messy data, clean it for analysis, draw meaningful visualizations from it, and impute missing values. See the [Readings section of the Resources tab on the course website](https://practicaldsc.org/resources/#readings) for supplemental resources.\n",
    "\n",
    "You are given six slip days throughout the semester to extend deadlines. See the [Syllabus](https://practicaldsc.org/syllabus) for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "To access this notebook, you'll need to clone our [public GitHub repository](https://github.com/practicaldsc/fa24/). The [⚙️ Environment Setup](https://practicaldsc.org/env-setup) page on the course website walks you through the necessary steps. Once you're done, you'll submit your completed notebook to Gradescope.\n",
    "\n",
    "Please start early and submit often. You can submit as many times as you'd like to Gradescope, and we'll grade your **most recent** submission. Remember that the public `grader.check` tests in your notebook are not comprehensive, and that your work will also be graded on hidden test cases on Gradescope after the submission deadline.\n",
    "\n",
    "This homework is worth a total of **40 points**, 31 of which come from the autograder, **and 9 of which are manually graded by us** (Questions 5.1 and 5.2). The number of points each question is worth is listed at the start of each question. **The three parts of the assignment are independent, so feel free to move around if you get stuck**. Tip: if you're using Jupyter Lab, you can see a Table of Contents for the notebook by going to View > Table of Contents.\n",
    "\n",
    "<a name='like-dataframe'>\n",
    "\n",
    "</a>\n",
    "\n",
    "<div class=\"alert alert-warning\" markdown=\"1\">\n",
    "    \n",
    "**Note**: Throughout this homework, you'll see statements like this frequently:\n",
    "\n",
    "<blockquote>Complete the implementation of the function ____, which takes in a DataFrame <code>df</code> like <code>other_df</code> and _____.</blockquote>\n",
    "\n",
    "What this means is that you should assume that `df` has the same number of columns as `other_df`, with the same column titles and data types, but potentially a different number of rows in a different order, with a potentially different index. You should always also assume that `df` has at least one row.\n",
    "\n",
    "We have you implement functions like this to prevent you from hard-coding your answers to one specific dataset.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\" markdown=\"1\">\n",
    "\n",
    "`for`-loops are **allowed** in Questions 3 and 7. `for`-loops are **not allowed** in Questions 1, 2, 4, 5, and 6.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e191200",
   "metadata": {},
   "source": [
    "To get started, run the **two** import cells below, plus the cell at the top of the notebook that imports and initializes `otter`. The first cell below installs a new package that wasn't included in the `pds` conda environment that we'll need for Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd5a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8847ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Preferred styles\n",
    "pio.templates[\"pds\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        width=600,\n",
    "        height=400,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+pds\"\n",
    "\n",
    "# Use plotly as default plotting engine\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "def save_and_show(fig, path):\n",
    "    plotly.io.write_image(fig, path, width=1200)\n",
    "    display(Image(path))\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf6338e",
   "metadata": {},
   "source": [
    "## Part 1: LendingClub Returns 💰\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8079d6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this part, we'll continue working with the LendingClub dataset from [Lecture 7](https://practicaldsc.org/resources/lectures/lec07/lec07-filled.html) and [Lecture 8](https://practicaldsc.org/resources/lectures/lec08/lec08-filled.html). Run the cell below to load in the file `'data/loans.csv'` as a DataFrame and clean it the way that we did in lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e37273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_term_column(df):\n",
    "    return df.assign(\n",
    "        term=df['term'].str.split().str[0].astype(int)\n",
    "    )\n",
    "    \n",
    "def clean_date_column(df):\n",
    "    return (\n",
    "        df\n",
    "        .assign(date=pd.to_datetime(df['issue_d'], format='%b-%Y'))\n",
    "        .drop(columns=['issue_d'])\n",
    "    )\n",
    "\n",
    "loans = (\n",
    "    pd.read_csv('data/loans.csv')\n",
    "    .pipe(clean_term_column)\n",
    "    .pipe(clean_date_column)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bf8b38",
   "metadata": {},
   "source": [
    "As a refresher, each row of the dataset corresponds to a different loan that the LendingClub approved and paid out. This is only a sample of all loans the LendingClub ever gave out, and remember, each row corresponds to an actually approved loan, **not** a loan application.\n",
    "\n",
    "Some of the key columns are:\n",
    "- `'loan_amnt' (float)`: The amount of the loan, or how much the borrower borrowed.\n",
    "- `'issue_d' (str)`: The date on which the loan was issued.\n",
    "- `'term' (str)`: The length of the loan, that is, the amount of time the borrower has to pay the loan back.\n",
    "- `'int_rate' (float)`: The interest rate the borrower will pay on their loan amount.\n",
    "- `'fico_range_low' (float)`: The borrower's credit score at the time of their application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a32fd76",
   "metadata": {},
   "source": [
    "In lecture, we drew visualizations to uncover a few key patterns in the data. We saw that:\n",
    "- Interest rates tend to be higher for 60 month loans than 36 month loans.\n",
    "- Borrowers with larger debt-to-income (DTI) ratios tend to receive higher interest rates than borrowers with lower DTIs.\n",
    "\n",
    "One feature we didn't use very much in our preliminary analyses was borrowers' credit scores. Both interest rate (`'int_rate'`) and credit score (`'fico_range_low'`) are numerical features, so to look at the relationship between them, we can use a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc63f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(loans, x='fico_range_low', y='int_rate',\n",
    "           labels={'fico_range_low': 'Credit Score', 'int_rate': 'Interest Rate (%)'},\n",
    "           title='Interest Rate vs. Credit Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98de4f1",
   "metadata": {},
   "source": [
    "There's a lot of overplotting here, meaning that many points are being plotted on top of one another. It does indeed seem that as credit scores increase, interest rates tend to decrease on average, but perhaps there's a better way to visualize this information.\n",
    "\n",
    "\n",
    "One idea is to place credit scores into categories by **binning** them. According to [Experian](https://www.experian.com/blogs/ask-experian/credit-education/score-basics/what-is-a-good-credit-score/#s1), one of the three major credit bureaus in the US, FICO credit scores are described qualitatively as follows:\n",
    "\n",
    "| Score | Category |\n",
    "|---|---|\n",
    "| 580 - 669 | Fair |\n",
    "| 670 - 739 | Good |\n",
    "| 740 - 799 | Very Good |\n",
    "| 800 - 850 | Excellent |\n",
    "\n",
    "There is actually also a bin below fair, named \"poor\" with a range of 300-579, but since `loans` doesn't have any poor credit scores, we'll exclude them from our exploration here. Note that while the `dtype` of `'fico_range_low'` is `float`, credit scores are actually integers.\n",
    "\n",
    "Once we place credit scores into bins, we can visualize the distribution of interest rates separately for each credit score bin. Here, that would allow us to draw four separate distributions of interest rates – one for the fair group, one for the good group, one for the very good group, and one for the excellent group. Each one of those four distributions are **numerical distributions**, which we have several tools for visualizing, including histograms, box plots, and violin plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b836777",
   "metadata": {},
   "source": [
    "### Question 1: Boxing Day 🥊 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "Complete the implementation of the function `create_boxplot`, which takes in a DataFrame `df` like `loans` and returns a `plotly` figure object containing a **box plot describing the distribution of interest rates, separately for each of the four credit score bins described below, and separately for the two loan lengths**. Here's an example of the plot you'll need to create:\n",
    "\n",
    "<center><img src=\"imgs/example-q1.png\" width=60%></center>\n",
    "\n",
    "To create your figure, you'll use the `px.box` function and provide several arguments. This [`plotly` article](https://plotly.com/python/box-plots/) will be extremely helpful.\n",
    "\n",
    "Before using `px.box`, though, you'll need to place credit scores into bins. There's a `pandas` function that will be helpful here. **Make sure the bins match those in our example plot exactly – inclusive of the left endpoint and exclusive of the right endpoint.** You'll need to hard-code these when creating your plot. You can assume that nobody has an exact credit score of 850. Once you've binned scores, you'll need to convert your Series of bin assignments to strings so that they can be used on the $x$-axis of a `px.box` figure.\n",
    "\n",
    "Some additional guidance:\n",
    "- Make sure your axis labels, legend labels, and title are the same as ours.\n",
    "- You **must** change the colors of the two terms from the default colors to something else. We chose purple and gold. To do this, you'll need to manually specify what color you want for the `36` group and the `60` group; it is fine to hard-code these two term lengths when creating your plot.\n",
    "\n",
    "Note that unlike in previous plotting questions, there **are** hidden tests, but they just check that the values in your plot are correct; the formatting is checked in the public tests. Remember that we will test `create_boxplot` on random samples of `loans`!\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "Once you're done implementing `create_boxplot`, please comment out the line at the bottom of the cell below that says `create_boxplot(loans)`; otherwise, we won't be able to manually grade your work!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b1731",
   "metadata": {
    "tags": [
     "to-py"
    ]
   },
   "outputs": [],
   "source": [
    "def create_boxplot(df):\n",
    "    ...\n",
    "\n",
    "# When you're ready to submit your homework, please comment the line below out;\n",
    "# otherwise, we won't be able to manually grade your work.\n",
    "create_boxplot(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be843475",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c7b90",
   "metadata": {},
   "source": [
    "If you created your box plot correctly, you should have seen a few things:\n",
    "- As borrowers' credit scores increase, both the median and variance in interest rates tend to decrease.\n",
    "- Across the spectrum of credit scores, 60 month loans tend to have higher interest rates than 36 month loans, which we'd seen before in our plots in lecture.\n",
    "\n",
    "Good to know!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5647df",
   "metadata": {},
   "source": [
    "Another factor that lenders like the LendingClub may look at when deciding whether or not to approve loans is the amount of **disposable income** potential borrowers have. With more disposable income, borrowers may be more likely to make their payments on time and less likely to **default** on their loans.\n",
    "\n",
    "Disposable income is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Disposable Income} = \\text{Gross Income} - \\text{Federal Income Tax} - \\text{State Income Tax} \n",
    "$$\n",
    "\n",
    "The `'annual_inc'` column in `loans` contains each borrower's gross income – that is, their income before taxes are removed. But it doesn't contain any information about the taxes that each borrower owes on their income.\n",
    "\n",
    "Run the cell below to define a DataFrame named `state_taxes_raw` that contains the tax brackets for each state in 2023 ([source](https://taxfoundation.org/data/all/state/state-income-tax-rates-2023/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58610d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_taxes_raw_path = 'data/state_taxes_raw.csv'\n",
    "state_taxes_raw = pd.read_csv(state_taxes_raw_path)\n",
    "state_taxes_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3177baf8",
   "metadata": {},
   "source": [
    "Above, this is saying that Alabama has three state income tax brackets:\n",
    "- Any income between \\\\$0 and \\\\$500 is taxed at 2%.\n",
    "- Any income between \\\\$500 and \\\\$3000 is taxed at 4%.\n",
    "- Any income above \\\\$3000 is taxed at 5%.\n",
    "\n",
    "These tax brackets are a mess! There are full rows of `NaN` values, not every row has a `'State'` filled in, and more. The brackets need more work to be compatible with, say, the `tax_owed` function we wrote in Homework 1. **In the next question, your job will be to reformatting the brackets in `state_taxes_raw` to be in a more useful format**. We won't actually go through the full process of computing disposable incomes, to be clear; you're just responsible for doing the cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeb3588",
   "metadata": {},
   "source": [
    "### Question 2: Death and Taxes 💵 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">7 Points</div>\n",
    "\n",
    "\n",
    "Complete the implementation of the function `state_brackets`, which takes in a DataFrame `df` like `state_taxes_raw`. It should return a DataFrame, indexed by `'State'`, with a single column, `'bracket_list'`, that contains the tax brackets for each `'State'` as **lists of tuples** in the form `(tax_rate, bracket_lower_limit)`.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> state_brackets(state_taxes_raw).head(4)\n",
    "```\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>bracket_list</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>State</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>Ala.</th>\n",
    "      <td>[(0.02, 0), (0.04, 500), (0.05, 3000)]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Alaska</th>\n",
    "      <td>[(0.0, 0)]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Ariz.</th>\n",
    "      <td>[(0.02, 0)]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Ark.</th>\n",
    "      <td>[(0.02, 0), (0.04, 4300), (0.05, 8500)]</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "Some added guidance:\n",
    "\n",
    "- In the returned DataFrame, `'State'`s should appear in the same order in which they appear in the input DataFrame `df`. \n",
    "\n",
    "- In each list of tuples in the returned `'State'` column, the tax rates themselves should be proportions, stored as floats (e.g. `0.02` instead of `2` to represent 2%), and the income amounts should be stored as integers. Round the tax rate proportions to two decimal places to avoid any floating point precision errors, and make sure to correctly account for states with no state income tax (like Alaska) as we did in the example.\n",
    "- If you're a little stuck on where to start, try to first clean the input DataFrame so it looks like the following DataFrame, and then figure out how to correctly group it:\n",
    "\n",
    "    <table border=\"1\" class=\"dataframe\">\n",
    "      <thead>\n",
    "        <tr style=\"text-align: right;\">\n",
    "          <th></th>\n",
    "          <th>State</th>\n",
    "          <th>Rate</th>\n",
    "          <th>Lower Limit</th>\n",
    "        </tr>\n",
    "      </thead>\n",
    "      <tbody>\n",
    "        <tr>\n",
    "          <th>0</th>\n",
    "          <td>Ala.</td>\n",
    "          <td>0.02</td>\n",
    "          <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <th>1</th>\n",
    "          <td>Ala.</td>\n",
    "          <td>0.04</td>\n",
    "          <td>500</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <th>2</th>\n",
    "          <td>Ala.</td>\n",
    "          <td>0.05</td>\n",
    "          <td>3000</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <th>4</th>\n",
    "          <td>Alaska</td>\n",
    "          <td>0.00</td>\n",
    "          <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <th>6</th>\n",
    "          <td>Ariz.</td>\n",
    "          <td>0.02</td>\n",
    "          <td>0</td>\n",
    "        </tr>\n",
    "      </tbody>\n",
    "    </table>\n",
    "\n",
    "- Make sure that any cleaning steps you perform are done within `state_brackets`, not directly to the `state_taxes_raw` DataFrame outside your notebook.\n",
    "- We will call your function on subsets of `state_taxes_raw`, but only subsets that are still well-formed, i.e. where all of the rows for a particular `'State'` are in order and formatted the same way they are in `state_taxes_raw` (no randomly sampled subsets).\n",
    "- You'll need to do some research to help you identify useful functions and methods to use (for instance, in how to fill in missing values in a particular way). For instance, you may need to `zip` ([documentation link](https://docs.python.org/3.3/library/functions.html#zip)) 🤐 at some point. \n",
    "- Don't forget that you can apply a function to every **row** of a DataFrame by using the DataFrame `apply` method with `axis=1`. `lambda` functions are your friend! 🫂\n",
    "- This is quite an involved problem. Try to organize your work as best as you can, for instance, **by using many helper functions** and the `pipe` DataFrame method. **Nothing about this question requires the use of a `for`-loop, so don't use one!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d32c2d",
   "metadata": {
    "tags": [
     "to-py"
    ]
   },
   "outputs": [],
   "source": [
    "def state_brackets(df):\n",
    "    ...\n",
    "\n",
    "# If you've completed the question correctly,\n",
    "# the first four rows below should match those in the\n",
    "# example above.\n",
    "state_brackets(state_taxes_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc824c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ee7153",
   "metadata": {},
   "source": [
    "## Part 2: Clean It Up 🧹\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc85cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 3: Reading Malformed CSVs <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "Up until now, most of the data we've had to work with was presented to us in a nice CSV file that we could call `pd.read_csv` on with no issues. But that won't always be the case! Sometimes there will be errors or problematic formatting.\n",
    "\n",
    "`'data/malformed.csv'` is a file of comma-separated values, containing the following fields:\n",
    "\n",
    "- `'first' (str)`: First name of person.\n",
    "- `'last' (str)`: Last name of person.\n",
    "- `'weight' (float)`: Weight of person (lbs).\n",
    "- `'height' (float)`: Height of person (in).\n",
    "- `'geo' (str)`: Location of person; comma-separated latitude/longitude.\n",
    "\n",
    "\n",
    "Unfortunately, the entries contains errors with the placement of commas (`,`) and quotes (`\"`) that cause `pd.read_csv` to fail parsing the file with the default settings. Don't believe us? Try using `pd.read_csv` on `'data/malformed.csv'` and look at what happens.\n",
    "\n",
    "As a result, instead of using `pd.read_csv`, you must read in the file manually using Python's built-in `open` function.\n",
    "\n",
    "Complete the implementation of the function `parse_malformed`, which takes in a string, `fp`, containing the path to a file, and returns a parsed, properly-typed DataFrame with the information in the corresponding file.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> parse_malformed('data/malformed.csv').head(3)\n",
    "```\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>first</th>\n",
    "      <th>last</th>\n",
    "      <th>weight</th>\n",
    "      <th>height</th>\n",
    "      <th>geo</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>Julia</td>\n",
    "      <td>Wagner</td>\n",
    "      <td>142.0</td>\n",
    "      <td>86.0</td>\n",
    "      <td>39.8,15.4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>Angelica</td>\n",
    "      <td>Rija</td>\n",
    "      <td>155.0</td>\n",
    "      <td>56.0</td>\n",
    "      <td>38.2,-71.7</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>Tyler</td>\n",
    "      <td>Micajah</td>\n",
    "      <td>116.0</td>\n",
    "      <td>73.0</td>\n",
    "      <td>38.0,6.9</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "Some guidance:\n",
    "- The only kinds of issues you need your function to handle are comma and quote misplacements; don't try and find any other issues with the CSV. \n",
    "- You should assume that `'data/malformed.csv'` is a sample of a larger file that has the same sorts of errors, but potentially in different lines. For example, `'data/malformed.csv'` has an unnecessary quote `\"` in line 4, but your function may be called on another CSV that has a perfectly fine line 4 but an unnecessary quote on some other line.\n",
    "- So, **don't** implement `parse_malformed` assuming that the commas and quotes are mispositioned on specific lines; rather, implement `parse_malformed` such that it can handle these issues on every single line they appear in. A good way to proceed is to open `'data/malformed.csv'` and look carefully at the comma and quote placements.\n",
    "- **You can** use a `for`-loop in this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c7432",
   "metadata": {
    "tags": [
     "to-py"
    ]
   },
   "outputs": [],
   "source": [
    "def parse_malformed(fp):\n",
    "    ...\n",
    "\n",
    "# If you've completed the question correctly,\n",
    "# the first three rows below should match those in the\n",
    "# example above.\n",
    "# Remember that we will call your function on\n",
    "# other similarly-formatted CSVs!\n",
    "parse_malformed('data/malformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb280e2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c09416",
   "metadata": {},
   "source": [
    "### Question 4: High Potential Individuals 📈 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "In 2022, the United Kingdom 🇬🇧 announced a new [\"High Potential Individual\" visa](https://www.gov.uk/high-potential-individual-visa/eligibility), which allows graduates of universities ranked in the Top 50 globally to move to the UK without a job lined up. This visa has been a subject of much debate, in part due to how much rankings play a role. Don't worry – the University of Michigan is on the list!\n",
    "\n",
    "In the next two questions, you will clean and analyze a dataset of university rankings, collected from  [here](https://www.kaggle.com/datasets/mylesoneill/world-university-rankings?datasetId=) (though we have pre-processed and modified the original dataset for the purposes of this question).\n",
    "\n",
    "Our version of the dataset is stored in `'data/universities.csv'`. We load it in as a DataFrame, `universities_raw`, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "universities_raw = pd.read_csv('data/universities.csv')\n",
    "universities_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d40ecd",
   "metadata": {},
   "source": [
    "Here are what the columns of `universities_raw` contain:\n",
    "\n",
    "- `'world_rank'`: World rank of the institution.\n",
    "- `'institution'`: Name of the institution.\n",
    "- `'national_rank'`: Rank within the nation, formatted as `'country, rank'`.\n",
    "- `'quality_of_education'`: Rank by quality of education.\n",
    "- `'alumni_employment'`: Rank by alumni employment.\n",
    "- `'quality_of_faculty'`: Rank by quality of faculty.\n",
    "- `'publications'`: Rank by publications.\n",
    "- `'influence'`: Rank by influence.\n",
    "- `'citations'`: Rank by number of citations.\n",
    "- `'broad_impact'`: Rank by broad impact.\n",
    "- `'patents'`: Rank by number of patents.\n",
    "- `'score'`: Overall score of the institution, out of 100.\n",
    "- `'control'`: Whether the university is public or private.\n",
    "- `'city'`: City in which the institution is located.\n",
    "- `'state'`: State in which the institution is located.\n",
    "\n",
    "There are (still) a few aspects of the dataset we need to clean before it's ready for analysis.\n",
    "\n",
    "Complete the implementation of the function `clean_universities`, which takes in a DataFrame `df` like `universities_raw` and returns a cleaned DataFrame, cleaned according to the following specifications:\n",
    "\n",
    "- Some `'institution'` names contain `'\\n'` characters (e.g. `'University of Michigan\\nAnn Arbor'`). Replace all instances of `'\\n'` with `', '` (a comma and a space) in the `'institution'` column.\n",
    "\n",
    "- Change the data type of the `'broad_impact'` column to `int`.\n",
    "\n",
    "- Split `'national_rank'` into two columns, `'nation'` and `'national_rank_cleaned'`, where:\n",
    "    - `'nation'` is the country (or its dependency) indicated in the first part of `'national_rank'`. \n",
    "        - Note that there are **3** countries that appear under different names for different schools. For all 3 of these countries, you should pick **the name that is longer** and use that name for every occurrence of the country. One of the 3 countries is **`'Czech Republic'`**, which also appears as **`'Czechia'`** – since these refer to the same country and `'Czech Republic'` is longer, all instances of either name should be replaced with `'Czech Republic'`. You need to find the other 2 countries on your own. \n",
    "        - These are the only 3 country names you need to handle.\n",
    "    - `'national_rank_cleaned'` is the integer in the latter part of `'national_rank'`. Make sure that the values in this column are stored as integers. \n",
    "    - Don't include the original `'national_rank'` column in the output DataFrame.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> clean_universities(universities).loc[[18], ['institution', 'nation', 'national_rank_cleaned']]\n",
    "```\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>institution</th>\n",
    "      <th>nation</th>\n",
    "      <th>national_rank_cleaned</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>18</th>\n",
    "      <td>University of Michigan, Ann Arbor</td>\n",
    "      <td>United States</td>\n",
    "      <td>15</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7db812",
   "metadata": {
    "tags": [
     "to-py"
    ]
   },
   "outputs": [],
   "source": [
    "def clean_universities(df):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "# A good strategy is to make sure it works when you call it on a random subset of universities_raw,\n",
    "# e.g. clean_universities(universities_raw.sample(100)).\n",
    "clean_universities(universities_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e06a85",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72830e",
   "metadata": {},
   "source": [
    "Once you're done Question 4, run the cell below to define a new DataFrame, `universities_cleaned`, that we'll use in Question 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414187f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "universities = clean_universities(universities_raw)\n",
    "universities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000fbb4",
   "metadata": {},
   "source": [
    "### Question 5: University of Practical Data Science 🏫\n",
    "\n",
    "Now that we have a cleaned DataFrame, `universities`, we can use it for analysis! Note that it's still not perfectly clean. Try and find the top 20 public `'institution'`s in the United States. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8938d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try and answer the question above here. It's not required, but you should explore – \n",
    "# we promise you'll find it interesting!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a477e3fe",
   "metadata": {},
   "source": [
    "#### Question 5.1 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "Many of the top `'institutions'` in the world, like Harvard University and the Massachusetts Institute of Technology, don't have the substring `'University of'` in their name. But many do, like University of Cambridge and, of course, University of Michigan, Ann Arbor. One may wonder, which schools have higher `'score'`s on average – schools with `'University of'` in their name, or schools without?\n",
    "\n",
    "Complete the implementation of the function `plot_university_of`, which takes in a DataFrame `df` like `universities` and returns a **`plotly` Figure object** depicting the distribution of `'score'`s, separately for `'institutions'` with and without `'University of'` in the title.\n",
    "\n",
    "Some guidance:\n",
    "- Names like \"Delft University of Technology\" count too – so `'University of'` doesn't have to be at the very start of the name. Similarly, if `'University Of Ann Arbor'` (capital O in \"Of\") was an `'institution'` in `df`, it should also count in the `'University of'` category.\n",
    "- Your plot should be such that it shows us at least _some_ of the `'score'`s for individual `'institutions'` directly. For example, in addition to some distributional information, we need to be able to see – perhaps by hovering – that Harvard University's `'score'` is 100.\n",
    "- Make sure your axis labels, legend labels, and title are all chosen manually by you: don't just use the defaults.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "Unlike other plots we've had you create in this class, this one will be manually graded, **not** autograded! To make sure we can grade your work correctly, once you're done implementing `plot_university_of`:\n",
    "\n",
    "1. Comment out the line at the bottom of the cell below, that just has `plot_university_of(universities)`.\n",
    "2. Run the cell that calls the function `save_and_show`. You should see a static (i.e. not interactive) version of your plot. This is to be expected. (This is what we'll use to grade your work.)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70604526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_university_of(df):\n",
    "    ...\n",
    "\n",
    "# When you're ready to submit your homework, please comment the line below out;\n",
    "# otherwise, we won't be able to manually grade your work.\n",
    "plot_university_of(universities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0456b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell, don't change anything.\n",
    "save_and_show(plot_university_of(universities), 'imgs/q05_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00020e1c",
   "metadata": {},
   "source": [
    "#### Question 5.2 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "One of the most important skills a data scientist needs to master is the ability to _think_ of questions. That's what you'll need to do here.\n",
    "\n",
    "**Your job is to think of an interesting question you might want to answer using the data `universities`, and then draw a visualization to help answer it.** Your visualization must involve at least one numerical feature and at least one categorical feature (potentially, one that you construct by taking an existing numerical feature and \"binning\" it, as we did in Question 1). The distribution of a single categorical feature is not _interesting_ enough, i.e. your question needs to be more sophisticated than \"Which states have the most public universities?\" with an accompanying bar chart.\n",
    "\n",
    "Complete the implementation of the function `custom_vis`, which takes in a DataFrame `df` like `universities` and returns a **`plotly` Figure object** containing your visualization. **Then, in the cell beneath it, tell us the question you tried to answer, and give us 1-2 sentences describing your takeaways.**\n",
    "\n",
    "This question will mostly be graded on effort. Meet the requirements above and you'll get full credit. That said, take pride in your work, and try your best to make a really special plot that others won't. Are you really proud of what you made? [**Post it in this Ed post**](https://edstem.org/us/courses/61012/discussion/5320217).\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "Like the plot above, this one will be manually graded, **not** autograded! To make sure we can grade your work correctly, once you're done implementing `custom_vis`:\n",
    "\n",
    "1. Comment out the line at the bottom of the cell above, that just has `custom_vis(universities)`.\n",
    "2. Run the cell that calls the function `save_and_show`. You should see a static (i.e. not interactive) version of your plot. This is to be expected. (This is what we'll use to grade your work.)\n",
    "\n",
    "Here, remember to provide your analysis of your plot in the cell below the one in which `save_and_show` is run.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284e90c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_vis(df):\n",
    "    ...\n",
    "\n",
    "# When you're ready to submit your homework, please comment the line below out;\n",
    "# otherwise, we won't be able to manually grade your work.\n",
    "custom_vis(universities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86b153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell, don't change anything.\n",
    "save_and_show(custom_vis(universities), 'imgs/q05_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c7463",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a7954",
   "metadata": {},
   "source": [
    "## Part 3: What's Missing? 👀\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b090c",
   "metadata": {},
   "source": [
    "In [Lecture 8](https://practicaldsc.org/resources/lectures/lec08/lec08-filled.html), we learned about different **imputation strategies** for filling in missing values. Here, we'll take things a step further and develop a few more related strategies.\n",
    "\n",
    "### Question 6: Conditioning on a Numerical Feature 🧍📏 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "In Lecture 8, you learned how to perform mean imputation conditionally on a **categorical** column: impute with the mean for each group. That is, for each distinct value of the **categorical** column, there is a single imputed value.\n",
    "\n",
    "Here, you will perform single-valued imputation by conditioning on a **numerical** column. This is not something we learned how to do in class. \n",
    "\n",
    "You will work with a version of the `heights` DataFrame from class, now called `new_heights`, that has a `'father'` column and a single `'child'` column. The `'child'` column has missing values. To impute the `'child'` column, transform the `'father'` column into a categorical column by binning the values of `'father'` into [quartiles](https://en.wikipedia.org/wiki/Quartile). Once this is done, you can impute `'child'` as in lecture (and described above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c63e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_heights = pd.read_csv('data/missing_heights.csv')\n",
    "new_heights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd3942",
   "metadata": {},
   "source": [
    "Complete the implementation of the function `cond_single_imputation`, which takes in a DataFrame `df` like `new_heights` with columns `'father'` and `'child'` (where `'child'` has missing values) and performs a single-valued mean imputation of the `'child'` column, conditional on `'father'`. `cond_single_imputation` should return a **Series** with just the imputed `'child'` heights.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> cond_single_imputation(new_heights).head(5)\n",
    "0    68.083871\n",
    "1    68.083871\n",
    "2    69.000000\n",
    "3    69.000000\n",
    "4    73.500000\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- There's likely a new `pandas` function you needed to research and use in Question 1. If you use that here, you'll be able to write a two-line solution.\n",
    "- If you use the `pandas` function above that we're talking about, you'll likely want to convert your column with group labels in it to hold type `str` (or `object`), otherwise you'll run into a `FutureWarning`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78889c9",
   "metadata": {
    "tags": [
     "to-py"
    ]
   },
   "outputs": [],
   "source": [
    "def cond_single_imputation(df):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "cond_single_imputation(new_heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10bbb5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f954359",
   "metadata": {},
   "source": [
    "### Question 7: Advanced Probabilistic Imputation 🎲 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "In [Lecture 8](https://practicaldsc.org/resources/lectures/lec08/lec08-filled.html), you learned how to impute a quantitative column by sampling from the observed values. **One problem with this technique is that the imputation will never generate imputed values that weren't already in the dataset.** For example, 57, 57.5, and 59 are values in the `'child'` column of `new_heights` while 58 is not. Thus, any imputation done by sampling from the observed values in the `'child'` column will not be able to generate a height of 58, even though it's clearly a reasonable value to occur in the dataset.\n",
    "\n",
    "To keep things simple, you will impute the `'child'` column **unconditionally** from the distribution of `'child'` heights present in the dataset. This means that you will use the values present in `'child'` to impute missing values, without looking at other columns.\n",
    "\n",
    "An approach to quantitative imputation that overcomes the limitation mentioned above is as follows:\n",
    "- Create a histogram of observed `'child'` heights, using 10 bins.\n",
    "- Use the histogram to generate a new `'child'` height to impute with, somewhere within the observed range of `'child'` heights:\n",
    "    - The probability a generated `'child'` height will come from a given bin is equal to the proportion of `'observed'` values in that bin. For example, if 20\\% of observed `'child'` heights fall within a particular bin, then there's a 20\\% chance we select that bin to draw a new `'child'` height from.\n",
    "    - Once we select a bin, any value within that bin's left and right endpoints is equally likely to be drawn. For example, if we selected the bin [12, 14), we could choose any real number between 12 (inclusive) and 14 (exclusive) to fill in as our missing `'child'` height; `np.random.uniform` can help us pick that number between 12 and 14.\n",
    "    \n",
    "Let's illustrate this approach with an example. Let `demo` be the array of 10 numbers defined below.\n",
    "\n",
    "```python\n",
    "demo = np.array([10, 11, 11, 13, 14, 14, 13.5, 14, 15, 16])\n",
    "```\n",
    "\n",
    "- The first step is creating a histogram of `demo`. Note that with this example dataset, we will use 4 bins, **but you will be using 10 bins** in your imputation process.\n",
    "\n",
    "<center><img src='imgs/histogram-demo.png' width=700></center>\n",
    "\n",
    "- Note that in your implementation, you don't actually need to draw a histogram – instead, use `np.histogram`. (Play around with it to figure out how it works.)\n",
    "- In the histogram above, we see that $\\frac{3}{10}$ of values lie in the [10, 12) bin, $\\frac{2}{10}$ of values lie in the [12, 14) bin, $\\frac{4}{10}$ of values lie in the [14, 16) bin, and $\\frac{1}{10}$ of values lie in the [16, 18] bin.\n",
    "- Next, we need to pick a bin at random. There's a 30\\% chance we pick the [10, 12) bin, a 20\\% chance we pick the [12, 14) bin, a 40\\% chance we pick the [14, 16) bin, and a 10\\% chance we pick the [16, 18] bin. `np.random.choice` will be helpful in picking a bin at random.\n",
    "- Once we pick a bin, we pick a number **uniformly at random** from within the bin. For instance, suppose we randomly chose the [14, 16) bin in the previous step. We then must select a (real) number between 14 and 16 uniformly at random; as mentioned above, `np.random.uniform` can help us here.\n",
    "\n",
    "Complete the implementation of the function `impute_height_quant`, which takes in a Series `s` like `heights['child']`, in which some values are missing, and returns a Series in which the values are imputed using the histogram scheme above. The length of the returned Series should be the same as the length of `s`.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> impute_height_quant(new_heights['child']).head(5)\n",
    "0    69.283202            # Randomly chosen!\n",
    "1    69.208524            # Randomly chosen!\n",
    "2    69.000000\n",
    "3    69.000000\n",
    "4    73.500000\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- You _can_ use a `for`-loop if needed.\n",
    "- As always, it's good practice to define a helper function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e03657",
   "metadata": {
    "tags": [
     "to-py"
    ]
   },
   "outputs": [],
   "source": [
    "def impute_height_quant(s):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "impute_height_quant(new_heights['child'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2fb299",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c860173f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Finish Line 🏁\n",
    "\n",
    "Congratulations! You're ready to submit Homework 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d6e43",
   "metadata": {},
   "source": [
    "To submit your homework:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope under \"Homework 4\".\n",
    "5. Stick around while the Gradescope autograder grades your work. Make sure you see that all **public tests** have passed on Gradescope. **Remember that homeworks have hidden tests, which you will not see your scores on until a few days after the deadline!**\n",
    "6. Check that you have a confirmation email from Gradescope and save it as proof of your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f1b4c7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd608c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "otter": {
   "tests": {
    "q01": {
     "name": "q01",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = create_boxplot(loans)\n>>> str(type(out)) == \"<class 'plotly.graph_objs._figure.Figure'>\"\nTrue",
         "failure_message": "Checking that create_boxplot returns a plotly Figure object. Failing this? Make sure you have `return fig` in your code!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = create_boxplot(loans)\n>>> out.data[0].type == 'box'\nTrue",
         "failure_message": "Checking that create_boxplot returns a box plot.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = create_boxplot(loans)\n>>> out.layout['title']['text'].lower().strip() == 'interest rate vs. credit score'\nTrue",
         "failure_message": "Checking that the box plot's title is correct.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = create_boxplot(loans)\n>>> (np.sort(np.unique(out.data[0]['x'])) == np.array(['[580, 670)', '[670, 740)', '[740, 800)', '[800, 850)'])).all()\nTrue",
         "failure_message": "Checking that the box plot's box category names are correct.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = create_boxplot(loans)\n>>> out.layout['xaxis']['title']['text'].lower().strip() == 'credit score range' \\\n... and out.layout['yaxis']['title']['text'].lower().strip() == 'interest rate (%)' \\\n... and out.layout['legend']['title']['text'].lower().strip() == 'loan length (months)'\nTrue",
         "failure_message": "Checking that the box plot's axis labels and legend are all correct.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = create_boxplot(loans)\n>>> colors = {out.data[i]['marker']['color'] for i in range(2)}\n>>> len(colors.intersection({'#1F77B4', '#FF7F0E'})) == 0\nTrue",
         "failure_message": "Checking that the box plot's colors are not the default colors.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02": {
     "name": "q02",
     "points": 7,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = state_brackets(pd.read_csv('data/state_taxes_raw.csv'))\n>>> type(out) == pd.DataFrame\nTrue",
         "failure_message": "Checking that state_brackets returns a DataFrame.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = state_brackets(pd.read_csv('data/state_taxes_raw.csv'))\n>>> (out.head(4).index == ['Ala.', 'Alaska', 'Ariz.', 'Ark.']).all()\nTrue",
         "failure_message": "Checking that the index is correct in the first four rows of the returned DataFrame.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = state_brackets(pd.read_csv('data/state_taxes_raw.csv'))\n>>> blist = out.head(4)['bracket_list']\n>>> list(blist) == [[(0.02, 0), (0.04, 500), (0.05, 3000)], [(0.0, 0)], [(0.02, 0)], [(0.02, 0), (0.04, 4300), (0.05, 8500)]] \nTrue",
         "failure_message": "Checking that the values are correct in the first four rows of the returned DataFrame.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q03": {
     "name": "q03",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = parse_malformed('data/malformed.csv')\n>>> (out.columns == ['first', 'last', 'weight', 'height', 'geo']).all()\nTrue",
         "failure_message": "Checking that the columns are named correctly.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = parse_malformed('data/malformed.csv')\n>>> (out.dtypes == ['object', 'object', 'float64', 'float64', 'object']).all()\nTrue",
         "failure_message": "Checking that the data types are set correctly.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = parse_malformed('data/malformed.csv')\n>>> out['geo'].str.contains(',').all()\nTrue",
         "failure_message": "Checking that all values in the 'geo' column contain commas.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = parse_malformed('data/malformed.csv')\n>>> out.shape == (100, 5)\nTrue",
         "failure_message": "Checking that the DataFrame has the right shape.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = parse_malformed('data/malformed.csv')\n>>> out.isna().sum().sum() == 0\nTrue",
         "failure_message": "Checking that there are no null values.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04": {
     "name": "q04",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = clean_universities(pd.read_csv('data/universities.csv'))\n>>> isinstance(out, pd.DataFrame) and out.shape == (1000, 16)\nTrue",
         "failure_message": "Checking that the returned DataFrame is of the correct shape.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = clean_universities(pd.read_csv('data/universities.csv'))\n>>> out['nation'].nunique() == 59\nTrue",
         "failure_message": "Checking that the number of unique nations is correct.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = clean_universities(pd.read_csv('data/universities.csv'))\n>>> (out[['nation', 'national_rank_cleaned', 'institution']].dtypes == ['object', 'int64', 'object']).all()\nTrue",
         "failure_message": "Checking that a few of the data types are correct.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = clean_universities(pd.read_csv('data/universities.csv'))\n>>> um = out.loc[18, ['institution', 'nation', 'national_rank_cleaned']]\n>>> um.iloc[0] == 'University of Michigan, Ann Arbor' and um.iloc[1] == 'United States' and um.iloc[2] == 15\nTrue",
         "failure_message": "Checking that the University of Michigan, Ann Arbor appears correctly.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = clean_universities(pd.read_csv('data/universities.csv'))\n>>> out['broad_impact'].dtype == 'int64'\nTrue",
         "failure_message": "Checking that the 'broad_impact' column's data type is correct.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q06": {
     "name": "q06",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = cond_single_imputation(pd.read_csv('data/missing_heights.csv'))\n>>> isinstance(out, pd.Series) and out.isna().sum() == 0\nTrue",
         "failure_message": "Checking that there are no longer any null values.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = cond_single_imputation(pd.read_csv('data/missing_heights.csv'))\n>>> new_heights['child'].mean() < out.mean()\nTrue",
         "failure_message": "Checking that the imputed mean is larger.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q07": {
     "name": "q07",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = impute_height_quant(pd.read_csv('data/missing_heights.csv')['child'])\n>>> isinstance(out, pd.Series) and np.isclose(out.min(), 56)\nTrue",
         "failure_message": "Checking that the minimum value in the imputed column is right.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = impute_height_quant(pd.read_csv('data/missing_heights.csv')['child'])\n>>> np.isclose(out.max(), 79)\nTrue",
         "failure_message": "Checking that the maximum value in the imputed column is right.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
