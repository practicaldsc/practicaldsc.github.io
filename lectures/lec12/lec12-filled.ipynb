{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc627d3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from lec_utils import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76a1f12",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "#### Lecture 12\n",
    "\n",
    "# Text as Data\n",
    "\n",
    "### EECS 398-003: Practical Data Science, Fall 2024\n",
    "\n",
    "<small><a style=\"text-decoration: none\" href=\"https://practicaldsc.org\">practicaldsc.org</a> ‚Ä¢ <a style=\"text-decoration: none\" href=\"https://github.com/practicaldsc/fa24\">github.com/practicaldsc/fa24</a></small>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4fd40",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements üì£\n",
    "\n",
    "- Homework 5 is due **tonight**. It includes a required [**Pre-Midterm Survey**](https://docs.google.com/forms/d/e/1FAIpQLSfCT2TfFUWF0gbnfuV_at0bG3w0Za9-KuLIA7cpZm0NL5jbKQ/viewform).<br><small>Homework 6 will be released later this week, but won't be due until after Fall Break.</small>\n",
    "- The Midterm Exam is on **Wednesday, October 9th from 7-9PM**.\n",
    "    - Lectures 1-12 and Homeworks 1-6 are in scope.\n",
    "    - The lecture before the exam will be review, and the TAs will run a review session on **Monday from 6-8PM in FXB 1109** too.\n",
    "    - You can bring **one double-sided 8.5\"x11\" notes sheet that you handwrite yourself (no printing, no using an iPad, etc.)**.\n",
    "    - Work through old exam problems [**here**](https://study.practicaldsc.org/).\n",
    "- Looking for sources of data, or other supplemental resources? Look at our updated [**Resources**](https://practicaldsc.org/resources) page!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed8c8d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: Following along with lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eceaa15",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- I've read the feedback, and I'll try and type slower and have slightly more of the code filled in the notebook before presenting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6fc450",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But, remember that **all** of the code I write live is posted **before lecture** ‚Äì click the **üìù filled html** buttons to see these (or open `lecXX-filled.ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13328a75",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- From text to numbers.\n",
    "- Bag of words üí∞.\n",
    "- TF-IDF.\n",
    "- Example: State of the Union addresses üé§."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d024ec",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "    <h3>Activity</h3><br><small>This is an old exam question!</small>\n",
    "\n",
    "<center><img src=\"imgs/practice.png\" width=1400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe519829",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "<small>Remember that you can always ask questions anonymously at the link above!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e02dc0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From text to numbers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fb09c4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From text to numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed13ab3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How do we represent a **text** document using **numbers**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79032ebb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Computers and mathematical formulas are designed to work with numbers, not words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cca7013",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So, if we can convert documents into numbers, we can:\n",
    "    - **summarize** documents by finding their most important words (today).\n",
    "    - **quantify** the similarity of two documents (today).\n",
    "    - use a document as input in a regression or classification model (second half of the semester)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3266c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: State of the Union addresses üé§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed060c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Each year, the sitting US President delivers a \"State of the Union\" address. The 2024 State of the Union (SOTU) address was on March 7th, 2024.<br><small>\"Address\" is another word for \"speech.\"</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bebde55",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('cplSUhU2avc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47309f8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The file `'data/stateoftheunion1790-2024.txt'` contains the transcript of every SOTU address since 1790."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98219531",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('data/stateoftheunion1790-2024.txt') as f:\n",
    "    sotu = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c75530",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The file is over 10 million characters long!\n",
    "len(sotu) / 1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf880775",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da044a6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In text analysis, each piece of text we want to analyze is called a **document**.<br><small>Here, each speech is a document.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd2201",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Documents are made up of **terms**, i.e. words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5022f187",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A collection of documents is called a **corpus**.<br><small>Here, the corpus is the set of all SOTU speeches from 1790-2024.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f814112",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extracting speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d315c4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the string `sotu`, each document is separated by `'***'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f57d1",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "speeches_lst = sotu.split('\\n***\\n')[1:]\n",
    "len(speeches_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad17b7a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that each \"speech\" currently contains other information, like the name of the president and the date of the address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078e8ae4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(speeches_lst[-1][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd03f5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's extract just the text of each speech and put it in a DataFrame.<br><small>Along the way, we'll use our new knowledge of regular expressions to remove capitalization and punctuation, so we can just focus on the content itself.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961ebdd",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_speeches_df(speeches_lst):\n",
    "    def extract_struct(speech):\n",
    "        L = speech.strip().split('\\n', maxsplit=3)\n",
    "        L[3] = re.sub(r\"[^A-Za-z' ]\", ' ', L[3]).lower() # Replaces anything OTHER than letters with ' '.\n",
    "        L[3] = re.sub(r\"it's\", 'it is', L[3])\n",
    "        return dict(zip(['president', 'date', 'text'], L[1:]))\n",
    "    speeches = pd.DataFrame(list(map(extract_struct, speeches_lst)))\n",
    "    speeches.index = speeches['president'].str.strip() + ': ' + speeches['date']\n",
    "    speeches = speeches[['text']]\n",
    "    return speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5123c7",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "speeches = create_speeches_df(speeches_lst)\n",
    "speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010eb4c8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quantifying speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd17a3b3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our goal is to produce a DataFrame that contains the **most important terms** in each speech, i.e. the terms that **best summarize** each speech:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>most important terms</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>George Washington: January 8, 1790</th>\n",
    "      <td>your, proper, regard, ought, object</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>George Washington: December 8, 1790</th>\n",
    "      <td>case, established, object, commerce, convention</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>...</th>\n",
    "      <td>...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Joseph R. Biden Jr.: February 7, 2023</th>\n",
    "      <td>americans, down, percent, jobs, tonight</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Joseph R. Biden Jr.: March 7, 2024</th>\n",
    "      <td>jobs, down, get, americans, tonight</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa532e7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To do so, we will need to come up with a way of assigning a **numerical score** to each term in each speech.<br><small>We'll come up with a score for each term such that terms with **higher scores** are **more important**!</small>\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>jobs</th>\n",
    "      <th>down</th>\n",
    "      <th>commerce</th>\n",
    "      <th>...</th>\n",
    "      <th>convention</th>\n",
    "      <th>americans</th>\n",
    "      <th>tonight</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>George Washington: January 8, 1790</th>\n",
    "      <td>0.00e+00</td>\n",
    "      <td>0.00e+00</td>\n",
    "      <td>3.55e-04</td>\n",
    "      <td>...</td>\n",
    "      <td>0.00e+00</td>\n",
    "      <td>0.00e+00</td>\n",
    "      <td>0.00e+00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>George Washington: December 8, 1790</th>\n",
    "      <td>0.00e+00</td>\n",
    "      <td>0.00e+00</td>\n",
    "      <td>1.10e-03</td>\n",
    "      <td>...</td>\n",
    "      <td>1.18e-03</td>\n",
    "      <td>0.00e+00</td>\n",
    "      <td>0.00e+00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>...</th>\n",
    "        <td>...</td>\n",
    "        <td>...</td>\n",
    "        <td>...</td>\n",
    "        <td>...</td>\n",
    "        <td>...</td>\n",
    "        <td>...</td>\n",
    "        <td>...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Joseph R. Biden Jr.: February 7, 2023</th>\n",
    "      <td>2.73e-03</td>\n",
    "      <td>1.78e-03</td>\n",
    "      <td>0.00e+00</td>\n",
    "      <td>...</td>\n",
    "      <td>0.00e+00</td>\n",
    "      <td>1.56e-03</td>\n",
    "      <td>3.34e-03</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Joseph R. Biden Jr.: March 7, 2024</th>\n",
    "      <td>1.77e-03</td>\n",
    "      <td>1.96e-03</td>\n",
    "      <td>5.93e-05</td>\n",
    "      <td>...</td>\n",
    "      <td>0.00e+00</td>\n",
    "      <td>2.37e-03</td>\n",
    "      <td>3.90e-03</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e201452",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In doing so, we will represent each speech as a **vector**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d489fc22",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bag of words üí∞\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b25e97",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Counting frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682706ac",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Idea**: The most important terms in a document are the terms that occur most often."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171244a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So, let's count the number of occurrences of each term in each document.<br><small>In other words, let's count the **frequency** of each term in each document.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3ba18",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For example, consider the following three documents:\n",
    "\n",
    "<div align=\"center\"><b>\n",
    "big big big big data class<br>\n",
    "data big data science<br>\n",
    "science big data\n",
    "    </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e61d52",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's construct a matrix, where:\n",
    "    - there is one row per **document**,\n",
    "    - one column per unique **term**, and\n",
    "    - the value in row $d$ and column $t$ is the **number of occurrences of term $t$ in document $d$**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db29d6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| | big | data | class |  science |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| **big big big big data class** | 4 | 1 | 1 | 0 |\n",
    "| **data big data science** | 1 | 2 | 0 | 1 |\n",
    "| **science big data** | 1 | 1 | 0 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed01710d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f0b36e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **bag of words** model represents documents as **vectors of word counts**, i.e. **term frequencies**.<br><small>The matrix below was created using the bag of words model.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8445a6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Each **row** in the bag of words matrix is a **vector representation** of a document.\n",
    "\n",
    "| | big | data | class |  science |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| **big big big big data class** | 4 | 1 | 1 | 0 |\n",
    "| **data big data science** | 1 | 2 | 0 | 1 |\n",
    "| **science big data** | 1 | 1 | 0 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b334d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For example, we can represent the document 2, **data big data science**, with the vector $\\vec{d_2}$:\n",
    "\n",
    "$$\\vec{d_2} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a595ae0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='imgs/bag-of-words.jpeg' width=1000></center>\n",
    "\n",
    "<center><a href=\"https://42f6861cgkip12ijm63i3orf-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/2020-07-bagofwords.jpg\">(source)</a></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center markdown=\"1\">It is called \"bag of words\" because it doesn't consider <b>order</b>.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c2aab",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: Interactive bag of words demo\n",
    "\n",
    "Check [this](https://svelte.dev/repl/98d158ef6fb842d09c66ed20b9a31e99?version=3.55.1) site out ‚Äì it automatically generates a bag of words matrix for you!\n",
    "\n",
    "<center><img src='imgs/bow-interactive.png' width=50%>(<a href=\"https://twitter.com/jdwlbr/status/1622704535511916544?s=20\">source</a>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ed879",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applications of the bag of words model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a26101",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now that we have a matrix of word counts, what can we do with it?\n",
    "\n",
    "| | big | data | class |  science |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| **big big big big data class** | 4 | 1 | 1 | 0 |\n",
    "| **data big data science** | 1 | 2 | 0 | 1 |\n",
    "| **science big data** | 1 | 1 | 0 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8eb47b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Application**: We _could_ interpret the term with the largest value ‚Äì that is, the **most frequent term** ‚Äì in each document as being the most important.<br><small>This is imperfect. What if a document has the term \"the\" as its most frequent term?</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd73e3fc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Application**: We could use the **vector** representations of documents to measure the **similarity** of two documents.<br><small>This would enable us to find, for example, the SOTU speeches that are most similar to one another!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b830ec5b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall: The dot product\n",
    "\n",
    "$$\\require{color}$$\n",
    "\n",
    "<div style=\"width: 100%;\">\n",
    "<div style=\"width: 65%; float: left\"> \n",
    "\n",
    "- Recall, if $\\color{purple} \\vec{u} = \\begin{bmatrix} u_1 \\\\ u_2 \\\\ ... \\\\ u_n \\end{bmatrix}$ and $\\color{#007aff} \\vec{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ ... \\\\ v_n \\end{bmatrix}$ are two vectors, then their <b>dot product</b> ${\\color{purple}\\vec{u}} \\cdot {\\color{#007aff}\\vec{v}}$ is defined as:\n",
    "\n",
    "$${\\color{purple}\\vec{u}} \\cdot {\\color{#007aff}\\vec{v}} = \\sum_{i = 1}^n {\\color{purple}u_i} {\\color{#007aff} v_i} = {\\color{purple}u_1} {\\color{#007aff} v_1} + {\\color{purple}u_2} {\\color{#007aff} v_2} + ... + {\\color{purple}u_n} {\\color{#007aff} v_n}$$\n",
    "\n",
    "- The dot product also has an equivalent **geometric** definition, which says that:\n",
    "\n",
    "$${\\color{purple}\\vec{u}} \\cdot {\\color{#007aff}\\vec{v}} = \\lVert {\\color{purple}\\vec{u}} \\rVert \\lVert {\\color{#007aff}\\vec{v}} \\rVert \\cos \\theta$$\n",
    "\n",
    "<center><small>where $\\theta$ is the angle between $\\color{purple}\\vec{u}$ and ${\\color{#007aff}\\vec{v}}$, and<br>$\\lVert {\\color{purple}\\vec{u}} \\rVert = \\sqrt{{\\color{purple} u_1}^2 + {\\color{purple} u_2}^2 + ... + {\\color{purple} u_n}^2}$<br>is the length of $\\color{purple} \\vec u$.</small></center>\n",
    "    \n",
    "- The two definitions are equivalent! This equivalence allows us to find the angle $\\theta$ between two vectors.\n",
    "    \n",
    "- For review, see [**LARDS, Section 2**](https://practicaldsc.org/lin-alg/#the-dot-product-angles-and-orthogonality).\n",
    "    \n",
    "</div>\n",
    "    <div style=\"margin-left: 65%; height: 100px;\" markdown=\"1\"> \n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/theta-1-unlabeled.png\" width=600>\n",
    "</center>\n",
    "\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e31ca9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Angles and similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74a0501",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- <b>Key idea</b>: The more similar two vectors are, the <b>smaller</b> the angle $\\theta$ between them is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62100721",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "    <div style=\"flex: 1; text-align: center;\">\n",
    "        <img src=\"imgs/theta-2.png\" width=\"415\">\n",
    "    </div>\n",
    "    <div style=\"flex: 1; text-align: center;\">\n",
    "        <img src=\"imgs/theta-1.png\" width=\"400\">\n",
    "    </div>\n",
    "    <div style=\"flex: 1; text-align: center;\">\n",
    "        <img src=\"imgs/theta-3.png\" width=\"415\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b164f0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The smaller the angle $\\theta$ between two vectors is, the **larger** $\\cos \\theta$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234961c0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The maximum value of $\\cos \\theta$ is 1, achieved when $\\theta = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87197e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key idea: The more similar two vectors are, the larger $\\cos \\theta$ is!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d57278",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774dba5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To measure the similarity between two documents, we can compute the **cosine similarity** of their vector representations:\n",
    "\n",
    "$$\\text{cosine similarity}(\\vec u, \\vec v) = \\cos \\theta = \\boxed{\\frac{\\vec{u} \\cdot \\vec{v}}{|\\vec{u}| | \\vec{v}|}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa28a834",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If all elements in $\\vec{u}$ and $\\vec{v}$ are non-negative, then $\\cos \\theta$ ranges from 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4fe5c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key idea: The more similar two vectors are, the larger $\\cos \\theta$ is!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdaa0b8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Given a collection of documents, to find the most similiar **pair**, we can:\n",
    "    1. Find the vector representation of each document.\n",
    "    2. Find the cosine similarity of each pair of vectors.\n",
    "    3. Return the documents whose vectors had the **largest** cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b81cae",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Activity</h3>\n",
    "\n",
    "Consider the matrix of word counts we found earlier, using the bag of words model:\n",
    "                \n",
    "| | big | data | class |  science |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| **big big big big data class** | 4 | 1 | 1 | 0 |\n",
    "| **data big data science** | 1 | 2 | 0 | 1 |\n",
    "| **science big data** | 1 | 1 | 0 | 1 |\n",
    "\n",
    "1. Which two documents have the highest **dot product**?\n",
    "2. Which two documents have the highest **cosine similarity**?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5611f1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f33bff",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why can't we just use the dot product ‚Äì that is, why must we divide by $|\\vec{u}| | \\vec{v}|$ when computing cosine similarity?\n",
    "\n",
    "$$\\text{cosine similarity}(\\vec u, \\vec v) = \\cos \\theta = \\boxed{\\frac{\\vec{u} \\cdot \\vec{v}}{|\\vec{u}| | \\vec{v}|}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176fa72c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| | big | data | class |  science |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| **big big big big data class** | 4 | 1 | 1 | 0 |\n",
    "| **data big data science** | 1 | 2 | 0 | 1 |\n",
    "| **science big data** | 1 | 1 | 0 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddaaa3a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Consider the following two _pairs_ of documents:\n",
    "\n",
    "| Pair | Dot Product | Cosine Similarity |\n",
    "| --- | --- | --- |\n",
    "| **big big big big data class** and **data big data science** | 6 | 0.577 |\n",
    "| **science big data** and **data big data science** | 4 | 0.943 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ecce8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **\"big big big big data class\"** has a large dot product with **\"data big data science\"** just because the former has the term **\"big\"** four times. But intuitively, **\"data big data science\"** and **\"science big data\"** should be much more similar, since they have almost the exact same terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804761b7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **So, make sure to compute the cosine similarity ‚Äì don't just use the dot product!**<br><small>If you don't normalize by the lengths of the vectors, documents with more terms will have artificially high similarities with other documents.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e786ee88",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\" markdown=\"1\">\n",
    "\n",
    "#### Reference Slide\n",
    "\n",
    "### Cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4163506",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Sometimes, you will see the **cosine distance** being used. It is the complement of cosine similarity:\n",
    "  \n",
    "$$\\text{dist}(\\vec{u}, \\vec{v}) = 1 - \\text{cosine similarity}(\\vec u, \\vec v) = 1 - \\cos \\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac8f6a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- If $\\text{dist}(\\vec{u}, \\vec{v})$ is small, the two vector representations are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae9d3aa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Issues with the bag of words model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6f8489",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Recall, the bag of words model encodes a document as a vector containing **word frequencies**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98164a1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It doesn't consider the **order** of the terms.\n",
    "<br><small>**\"big data science\"** and **\"data science big\"** have the same vector representation, but mean different things.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8716cc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It doesn't consider the **meaning** of terms.<br><small>**\"I really really hate data\"** and **\"I really really love data\"** have nearly identical vector representations, but very different meanings.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195062e8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It treats all words as being equally important. **This is the issue we'll address today.**<br><small>In **\"I am a student\"** and **\"I am a teacher\"**, it's clear to us humans that the most important terms are **\"student\"** and **\"teacher\"**, respectively. But in the bag of words model, **\"student\"** and **\"I\"** appear the same number of times in the first document.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d5596",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "<small>Remember that you can always ask questions anonymously at the link above!</small>\n",
    "    \n",
    "What questions do you have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3cafc7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TF-IDF\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae9da5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What makes a word important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210246b3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Issue**: The bag of words model doesn't know which terms are \"important\" in a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5998e8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Consider the following document:\n",
    "\n",
    "<center>\"my brother has a friend named <b>billy</b> who has an uncle named <b>billy</b>\"</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9872d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **\"has\"** and **\"billy\"** both appear the same number of times in the document above. But **\"has\"** is an extremely common term overall, while **\"billy\"** isn't."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088abb3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Observation**: If a term is important in a document, it will **appear frequently in that document** but **not frequently in other documents**.<br><small>Let's try and find a way of giving **scores** to terms that keeps this in mind. If we can do this, then the terms with the highest scores can be used to summarize the document!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc4906",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327360e3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **term frequency** of a term $t$ in a document $d$, denoted $\\text{tf}(t, d)$, is the proportion of words in document $d$ that are equal to $t$.\n",
    "\n",
    "$$\\text{tf}(t, d) = \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of terms in $d$}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d0d929",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example**: What is the term frequency of \"billy\" in the following document?\n",
    "\n",
    "<center>\"my brother has a friend named <b>billy</b> who has an uncle named <b>billy</b>\"</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74157531",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer**: $\\frac{2}{13}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1971121",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Intuition: Terms that occur often within a document are important to the document's meaning.\n",
    "\n",
    "$$\\text{tf}(t, d) \\text{ large} \\implies t \\text{ occurs often in $d$} \\\\ \\text{tf}(t, d) \\text{ small} \\implies t \\text{ occurs rarely in $d$}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ccf42",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Issue: **\"has\"** also has a TF of $\\frac{2}{13}$, but it seems less important than **\"billy\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9732f8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inverse document frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c57ebd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **inverse document frequency** of a term $t$ in a **set** of documents $d_1, d_2, ...$ is:\n",
    "\n",
    "$$\\text{idf}(t) = \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a986a09",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example**: What is the inverse document frequency of **\"billy\"** in the following three documents?\n",
    "    - \"my brother has a friend named **billy** who has an uncle named **billy**\"\n",
    "    - \"my favorite artist is named jilly boel\"\n",
    "    - \"why does he talk about someone named **billy** so often\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e89df",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer**: $\\log \\left(\\frac{3}{2}\\right) \\approx 0.4055$.<br><small>Here, we used the natural logarithm. It doesn't matter which log base we use, as long as we keep it consistent throughout all of our calculations.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df281a7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Intuition: If a word appears in every document (like **\"the\"** or **\"has\"**), it is probably not a good summary of any one document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb83bd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Think of $\\text{idf}(t)$ as the \"rarity factor\" of $t$ across documents ‚Äì the larger $\\text{idf}(t)$ is, the more rare $t$ is.\n",
    "\n",
    "$$\\text{idf}(t) \\text{ large} \\implies t \\text{ rare across all documents} \\\\ \\text{idf}(t) \\text{ small} \\implies t \\text{ common across all documents}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ec11a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd6cab",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Goal**: Measure how important term $t$ is to document $d$.<br><small>Equivalent goal: Find the terms that best summarize $d$.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aab5187",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{tf}(t, d) = \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of terms in $d$}}$$\n",
    "\n",
    "$$\\text{idf}(t) = \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cad0006",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{tf}(t, d)$ is small, then $t$ doesn't occur very often in $d$, so $t$ can't be very important to $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152257bb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{idf}(t)$ is small, then $t$ occurs often amongst all documents, and so it can't be very important to $d$ specifically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d115c348",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{tf}(t, d)$ and $\\text{idf}(t)$ are both large, then **$t$ occurs often in $d$ but rarely overall**. This makes $t$ **important** to $d$, i.e. a good \"summary\" of $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92238e7d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term frequency-inverse document frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1171e779",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **term frequency-inverse document frequency (TF-IDF)** of term $t$ in document $d$ is the product:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\text{tfidf}(t, d) &= \\text{tf}(t, d) \\cdot \\text{idf}(t) \\\\\\ &= \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of terms in $d$}} \\cdot \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right) \\end{align*} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c1648b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{tfidf}(t, d)$ is large, then $t$ is important to $d$, because $t$ occurs often in $d$ but rarely across all documents.<br><small>This means $t$ is a good summary of $d$!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744506c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note: TF-IDF is a **heuristic** method ‚Äì there's no \"proof\" that it performs well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e973837f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To know if $\\text{tfidf}(t, d)$ is large for one particular term $t$, we need to compare it to $\\text{tfidf}(t_i, d)$, for several different terms $t_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2889d4d7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35900803",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: What is the TF-IDF of **\"science\"** in **\"data big data science\"**?\n",
    "\n",
    "\n",
    "| | big | data | class |  science |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| **big big big big data class** | 4 | 1 | 1 | 0 |\n",
    "| **data big data science** | 1 | 2 | 0 | 1 |\n",
    "| **science big data** | 1 | 1 | 0 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64224a7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer**:\n",
    "\n",
    "$$\\begin{align*}\\text{tfidf}(t, d) &= \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of terms in $d$}} \\cdot \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right) \\\\ &= \\frac{1}{4} \\cdot \\log\\left( \\frac{3}{2} \\right)\\end{align*} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35f262",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Is this big or small? Is **\"science\"** the **best** summary of **\"data big data science\"**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7ff70",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TF-IDF of all terms in all documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308031f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- On its own, the TF-IDF of one term in one document doesn't really tell us anything. We must compare it to TF-IDFs of other terms in that same document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1fb15",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's start with a DataFrame version of our bag of words matrix. It already contains the numerators for term frequency, i.e. $\\text{tf}(t, d) = \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of terms in $d$}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e63f0",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "| | big | data | class |  science |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| **big big big big data class** | 4 | 1 | 1 | 0 |\n",
    "| **data big data science** | 1 | 2 | 0 | 1 |\n",
    "| **science big data** | 1 | 1 | 0 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76db60",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bow = pd.DataFrame([[4, 1, 1, 0], [1, 2, 0, 1], [1, 1, 0, 1]],\n",
    "                   index=['big big big big data class', 'data big data science', 'science big data'],\n",
    "                   columns=['big', 'data', 'class', 'science'])\n",
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc78aef",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To convert the term counts to **term frequencies**, we'll divide by the sum of each **row**.<br><small>Each row corresponds to the terms in one document; the sum of a row is the total number of terms in the document, which is the denominator in $\\text{tf}(t, d) = \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of terms in $d$}}$.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e96ae",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Verify that each row sums to 1!\n",
    "tfs = bow.apply(lambda s: s / s.sum(), axis=1) \n",
    "tfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69752e7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Next, we need to find the **inverse document frequency** of each term, $t$, where $\\text{idf}(t) = \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d5712",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def idf(term):\n",
    "    term_column = tfs[term]\n",
    "    return np.log(term_column.shape[0] / (term_column > 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eefe380",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idf('class') == np.log(3 / 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3c00d0",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_idfs = [idf(c) for c in tfs.columns] \n",
    "all_idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2bfb3a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_idfs = pd.Series(all_idfs, index=tfs.columns)\n",
    "all_idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e9947",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Finally, let's multiply `tfs`, the DataFrame with the term frequencies of each term in each document, by `all_idfs`, the Series of inverse document frequencies of each term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd6709",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfidfs = tfs * all_idfs \n",
    "tfidfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e2bd74",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpreting TF-IDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d24a3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfidfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a30345",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The TF-IDF of `'class'` in the first sentence is $\\approx 0.18$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef15ee9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The TF-IDF of `'data'` in the second sentence is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ad2ed",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that there are two ways that $\\text{tfidf}(t, d) = \\text{tf}(t, d) \\cdot \\text{idf}(t)$ can be 0:\n",
    "    - If $t$ appears in every document, because then $\\text{idf}(t) = \\log (\\frac{\\text{# documents}}{\\text{# documents}}) = \\log(1) = 0$.\n",
    "    - If $t$ does not appear in document $d$, because then $\\text{tf}(t, d) = \\frac{0}{\\text{len}(d)} = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bfbece",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The term that **best summarizes** a document is the term with the highest TF-IDF for that document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d521d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfidfs.idxmax(axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50251cf6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "<small>Remember that you can always ask questions anonymously at the link above!</small>\n",
    "    \n",
    "What questions do you have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6527a0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: State of the Union addresses üé§\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538c379e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8811bd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now that we have a robust technique for assigning scores to terms ‚Äì that is, TF-IDF ‚Äì we can use it to find the most important terms in each State of the Union address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de0b38",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1176e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To recap, we'll need to compute:\n",
    "\n",
    "```\n",
    "        for each term t:\n",
    "            for each speech d:\n",
    "                compute tfidf(t, d)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f5bf0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This time, we don't already have a bag of words matrix, so we'll need to start from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb92bb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding all unique terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b921526",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- First, we need to find the unique terms used across all SOTU speeches.<br><small>These words will form the **columns** of our TF-IDF matrix.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1973eb7b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_unique_terms = speeches['text'].str.split().explode().value_counts() # Faster than .sum() from last lecture! \n",
    "all_unique_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027df8f8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since there are over 20,000 unique terms, our future calculations will otherwise take too much time to run. Let's take the 500 most frequent, across all speeches, for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb1f27",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "unique_terms = all_unique_terms.iloc[:500].index \n",
    "unique_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cdd026",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding term frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d68d35",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Next, let's find the bag of words matrix, i.e. a matrix that tells us the number of occurrences of each term in each document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16270cad",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What's the difference between the following two expressions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1113493d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "speeches['text'].str.count('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d1530",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remember, the \\b special character matches **word boundaries**!\n",
    "# This makes sure that we don't count instances of \"the\" that are part of other words,\n",
    "# like \"thesaurus\".\n",
    "speeches['text'].str.count(r'\\bthe\\b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c2a4bd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's repeat the above calculation for every unique term. This code will take a while to run, so we'll use the `tdqm` package to track its progress.<br><small>Install with `mamba install tqdm` if needed.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd7f40",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "counts_dict = {}\n",
    "for term in tqdm(unique_terms):\n",
    "    counts_dict[term] = speeches['text'].str.count(fr'\\b{term}\\b')        \n",
    "counts = pd.DataFrame(counts_dict, index=speeches.index)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac826561",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The above DataFrame **does not** contain term frequencies. To convert the values above to term frequencies, we need to normalize by the sum of each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5bf22b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfs = counts.apply(lambda s: s / s.sum(), axis=1)\n",
    "tfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7e0a7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding TF-IDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc539eb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Finally, we'll need to find the inverse document frequencies (IDF) of each term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2b58fa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Using `apply`, we can find the IDFs of each term **and** multiply them by the term frequencies in one step.\n",
    "\n",
    "$$\\begin{align*}\\text{tfidf}(t, d) &= \\underbrace{\\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of terms in $d$}}}_{\\text{we already computed these}} \\cdot \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right)\\end{align*} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36212230",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfidfs = tfs.apply(lambda s: s * np.log(s.shape[0] / (s > 0).sum())) \n",
    "tfidfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbb6c11",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why are the TF-IDFs of many common words 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f359642",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b99fd5d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- By using `idxmax`, we can find the term with the highest TF-IDF in each speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d35d8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "summaries = tfidfs.idxmax(axis=1) \n",
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b2656",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What if we want to see the 5 terms with the highest TF-IDFs, for each speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62914083",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def five_largest(row):\n",
    "    return ', '.join(row.index[row.argsort()][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f61c945",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keywords = tfidfs.apply(five_largest, axis=1).to_frame().rename(columns={0: 'most important terms'})\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ec2b3e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Uncomment the cell below to see every single row of `keywords`.<br><small>Cool!</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eecd06",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display_df(keywords, rows=234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a6aaa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cosine similarity, revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a00468",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Each row of `tfidfs` contains a vector representation of a speech. This means that we can compute the cosine similarities between any two speeches!<br><small>The only difference now is that we used TF-IDF to find $\\vec u$ and $\\vec v$, rather than the bag of words model.</small>\n",
    "\n",
    "$$\\text{cosine similarity}(\\vec u, \\vec v) = \\frac{\\vec{u} \\cdot \\vec{v}}{|\\vec{u}| | \\vec{v}|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee568b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1af9e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sim(speech_1, speech_2):\n",
    "    v1 = tfidfs.loc[speech_1]\n",
    "    v2 = tfidfs.loc[speech_2]\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d48437",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sim('George Washington: January 8, 1790', 'George Washington: December 8, 1790')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94656eb6",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sim('George Washington: January 8, 1790', 'Joseph R. Biden Jr.: March 7, 2024')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ac0f5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can also find the **most similar** pair of speeches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f2eb8a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc4caa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sims_dict = {}\n",
    "# For every pair of speeches, find the similarity and store it in\n",
    "# the sims_dict dictionary.\n",
    "for pair in combinations(tfidfs.index, 2):\n",
    "    sims_dict[pair] = sim(pair[0], pair[1])\n",
    "# Turn the sims_dict dictionary into a DataFrame.\n",
    "sims = (\n",
    "    pd.Series(sims_dict)\n",
    "    .reset_index()\n",
    "    .rename(columns={'level_0': 'speech 1', 'level_1': 'speech 2', 0: 'cosine similarity'})\n",
    "    .sort_values('cosine similarity', ascending=False)\n",
    ")\n",
    "sims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15cc345",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For instance, we can find the most similar pairs of speeches by **different** Presidents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85663fb",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sims[sims['speech 1'].str.split(':').str[0] != sims['speech 2'].str.split(':').str[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01f74c8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: What if we remove the $\\log$ from $\\text{idf}(t)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a56203b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's try it and see what happens.<br><small>Below is another, quicker implementation of how we might find TF-IDFs.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9cdc68",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfidfs_nl_dict = {}\n",
    "tf_denom = speeches['text'].str.split().str.len()\n",
    "for word in tqdm(unique_terms):\n",
    "    re_pat = fr' {word} ' # Imperfect pattern for speed.\n",
    "    tf = speeches['text'].str.count(re_pat) / tf_denom\n",
    "    idf_nl = len(speeches) / speeches['text'].str.contains(re_pat).sum()\n",
    "    tfidfs_nl_dict[word] =  tf * idf_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d7524",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfidfs_nl = pd.DataFrame(tfidfs_nl_dict)\n",
    "tfidfs_nl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be80625",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keywords_nl = tfidfs_nl.apply(five_largest, axis=1)\n",
    "keywords_nl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f53d2ff",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da538f5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The role of $\\log$ in $\\text{idf}(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d09ae1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align*}\\text{tfidf}(t, d) &= \\text{tf}(t, d) \\cdot \\text{idf}(t) \\\\\\ &= \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of terms in $d$}} \\cdot \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right) \\end{align*} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e69384d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Remember, for any positive input $x$, $\\log(x)$ is (much) smaller than $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf8c8c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In $\\text{idf}(t)$, the $\\log$ \"dampens\" the impact of the ratio $\\frac{\\text{# documents}}{\\text{# documents with $t$}}$. **If a word is very common, the ratio will be close to 1. The log of the ratio will be close to 0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac893c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "(1000 / 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be05c8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.log(1000 / 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b670fa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If a word is very common (e.g. **\"the\"**), and we didn't have the $\\log$, we'd be multiplying the term frequency by a large factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b4f4d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If a word is very rare, the ratio $\\frac{\\text{# documents}}{\\text{# documents with $t$}}$ will be very large. However, for instance, a word being seen in **2 out of 50** documents is not very different than being seen in **2 out of 500** documents (it is very rare in both cases), and so $\\text{idf}(t)$ should be similar in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6a87a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "(50 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58ae81",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "(500 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f6c54",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.log(50 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd1851f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.log(500 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1209671e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Activity</h3><small>This is an old exam question!</small>\n",
    "    \n",
    "Nishant decides to look at reviews for the Catamaran Resort Hotel and Spa. TripAdvisor has 96 reviews for the hotel; of those 96, Nishant‚Äôs favorite review was:\n",
    "    \n",
    "**\"close to the beach but far from the beach beach\"**\n",
    "    \n",
    "1. What is the TF of **\"beach\"** in Nishant‚Äôs favorite review? Give your answer as a simplified fraction.\n",
    "1. The TF-IDF of **\"beach\"** in Nishant‚Äôs favorite review is $\\frac{9}{10}$, when using a base-2 logarithm to compute the IDF. How many of the reviews on TripAdvisor for this hotel contain the term **\"beach\"**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af93ac2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TF-IDF, implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd74949",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In Homework 6, we may ask you to implement TF-IDF to further your own understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d39dd8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But, in practical projects, you'd use an existing implementation of it, like `TfIdfVectorizer` in `sklearn`.<br><small>See [**the documentation**](https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) for more details.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15b09f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c0831c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(speeches['text'])\n",
    "tfidfs_sklearn = pd.DataFrame(X.toarray(), \n",
    "                              columns=vectorizer.get_feature_names_out(), \n",
    "                              index=speeches.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b3b60e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfidfs_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7fa5f4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfidfs_sklearn[tfidfs_sklearn['zuloaga'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2307823c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- One way to turn text, like `'big big big big data classs'`, into numbers, is to count the number of occurrences of each word in the document, ignoring order. This is done using the **bag of words** model.\n",
    "- Term frequency-inverse document frequency (TF-IDF) is a statistic that tries to quantify how **important** a term (word) is to a document. It balances:\n",
    "    - **how often a term appears in a particular document**, $\\text{tf}(t, d)$, with\n",
    "    - **how often a term appears across documents**, $\\text{idf}(t)$.\n",
    "    - For a given document, the word with the highest TF-IDF is thought to \"best summarize\" that document.\n",
    "- Both the bag of words model and TF-IDF are ways of converting texts to **vector representations**.\n",
    "- To measure the similarity of two texts, convert the texts to their vector representations, and use cosine similarity."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
