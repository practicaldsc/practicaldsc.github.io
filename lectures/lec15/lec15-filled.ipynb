{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be938ea3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from lec_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e4b68",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "#### Lecture 15 Supplementary Notebook\n",
    "\n",
    "# Simple Linear Regression\n",
    "\n",
    "### EECS 398-003: Practical Data Science, Fall 2024\n",
    "\n",
    "<small><a style=\"text-decoration: none\" href=\"https://practicaldsc.org\">practicaldsc.org</a> â€¢ <a style=\"text-decoration: none\" href=\"https://github.com/practicaldsc/fa24\">github.com/practicaldsc/fa24</a></small>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Note**: This notebook is only a supplementary notebook to the main lecture slides, which are in PDF form.\n",
    "\n",
    "The main lecture slides can be found at [practicaldsc.org](https://practicaldsc.org) under Lecture 15. (After the live lecture, an annotated version of the slides will be made available as well.)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83952d7e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Understanding the Data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d3e44",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's load in the commute times dataset as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71c8d3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/commute-times.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a97e8f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "There are many columns in here, but the only ones we're interested in for now are `'departure_hour'` and `'minutes'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44c8d6c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df[['departure_hour', 'minutes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333c4ed",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df,\n",
    "           x='departure_hour',\n",
    "           y='minutes',\n",
    "           size=np.ones(len(df)) * 50,\n",
    "           size_max=8)\n",
    "fig.update_xaxes(title='Home Departure Time (AM)')\n",
    "fig.update_yaxes(title='Minutes')\n",
    "fig.update_layout(title='Commuting Time vs. Home Departure Time')\n",
    "fig.update_layout(width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb90662",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implementing $w_0^*$ and $w_1^*$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9affc2",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's implement the formulas for the best slope, $w_1^*$, and intercept, $w_0^*$, we found in the lecture slides:\n",
    "\n",
    "\\begin{align*}\n",
    "w_1^* &=\n",
    "    \\frac{\n",
    "        \\displaystyle\n",
    "        \\sum_{i=1}^n (x_i - \\bar x)(y_i - \\bar y)\n",
    "    }{\n",
    "        \\displaystyle\n",
    "        \\sum_{i=1}^n (x_i - \\bar x)^2\n",
    "    }\n",
    "    \\qquad\n",
    "    \\qquad\n",
    "w_0^* =\n",
    "    \\bar y - w_1^* \\bar x\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08035d6",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def slope(x, y):\n",
    "    # Assume x and y are two Series.\n",
    "    numerator = ((x - np.mean(x)) * (y - np.mean(y))).sum()\n",
    "    denominator = ((x - np.mean(x)) ** 2).sum()\n",
    "    return numerator / denominator\n",
    "def intercept(x, y):\n",
    "    return y.mean() - slope(x, y) * x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2875e60",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w1_star = slope(df['departure_hour'], df['minutes'])\n",
    "w1_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e92048",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w0_star = intercept(df['departure_hour'], df['minutes'])\n",
    "w0_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35445ec",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The results above tell us that the linear hypothesis function with the lowest mean squared error on our dataset is:\n",
    "\n",
    "$$\\text{predicted commute time (minutes)} = 142.45 - 8.19 \\cdot \\text{departure hour}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d08e8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can use it to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c380ae2",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_commute(x_new):\n",
    "    return w0_star + w1_star * x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535086fd",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What if I leave at 8AM? 10:45AM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1671c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predict_commute(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e36029",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predict_commute(10 + 45 / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cda7663",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What do all of our predictions look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01482005",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hline = px.line(x=[5.5, 11.5], y=[predict_commute(5.5), predict_commute(11.5)]).update_traces(line={'color': 'red', 'width': 4})\n",
    "fline1 = go.Figure(fig.data + hline.data)\n",
    "fline1.update_xaxes(title='Home Departure Time (AM)')\n",
    "fline1.update_yaxes(title='Minutes')\n",
    "fline1.update_layout(title='<span style=\"color:red\">Predicted Commute Time</span> = 142.25 - 8.19 * Departure Hour')\n",
    "fline1.update_layout(width=700, margin={'t': 60})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187765e3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Aside: What does $R_{\\text{sq}}(w_0, w_1)$ look like?\n",
    "\n",
    "Let's draw a plot of $R_{\\text{sq}}(w_0, w_1)$, the empirical risk that we're trying to minimize.\n",
    "- When we only had a single parameter, $h$, $R(h)$ was in 2D.\n",
    "    - One axis for $h$, one axis for $R(h)$.\n",
    "- Now that we have two parameters, $w_0$ and $w_1$, $R(w_0, w_1)$ will be in 3D!\n",
    "    - One axis for $w_0$, one axis for $w_1$, one axis for $R(w_0, w_1)$.\n",
    "    - The bottom plane consists of all possible combinations of slope and intercept.\n",
    "    - The height of the function above any pair of points on the bottom plane represents the MSE for that combination of slope and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d742e8d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def mse(y_actual, y_pred):\n",
    "    return np.mean((y_actual - y_pred)**2)\n",
    "def mse_for_departure_model(w):\n",
    "    w0, w1 = w\n",
    "    return mse(df['minutes'], w0 + w1 * df['departure_hour'])\n",
    "num_points = 50 # increase for better resolution, but it will run more slowly. \n",
    "# if (num_points <= 100):\n",
    "uvalues = np.linspace(90, 190, num_points)\n",
    "vvalues = np.linspace(-13, -3, num_points)\n",
    "(u,v) = np.meshgrid(uvalues, vvalues)\n",
    "thetas = np.vstack((u.flatten(),v.flatten()))\n",
    "MSE = np.array([mse_for_departure_model(t) for t in thetas.T])\n",
    "loss_surface = go.Surface(x=u, y=v, z=np.reshape(MSE, u.shape))\n",
    "minimizer = go.Scatter3d(x=[w0_star], y=[w1_star], z=[mse_for_departure_model([w0_star, w1_star])], \n",
    "                         mode='markers', name='optimal parameters',\n",
    "                         marker=dict(size=10, color='gold'))\n",
    "fig = go.Figure(data=[loss_surface, minimizer])\n",
    "# fig.add_trace(opt_point)\n",
    "fig.update_layout(title='Loss Surface', scene = dict(\n",
    "    xaxis_title = \"w0\",\n",
    "    yaxis_title = \"w1\",\n",
    "    zaxis_title = r\"R(w0, w1)\"))\n",
    "fig.show()\n",
    "# else:\n",
    "#     print(\"Picking num points > 100 can be really slow. If you really want to try, edit the code above so that this if statement doesn't trigger.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c734ce",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We used partial derivatives to minimize the graph above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26184eb",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Correlation\n",
    "\n",
    "---\n",
    "\n",
    "$$\\begin{align*} r &= \\text{the average of the product of $x$ and $y$, when both are standardized} \\\\ &= \\frac{1}{n} \\sum_{i = 1}^n \\left( \\frac{x_i - \\bar{x}}{\\sigma_x} \\right) \\left( \\frac{y_i - \\bar{y}}{\\sigma_y} \\right)  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b58de",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def correlation(x, y): \n",
    "    x_su = (x - np.mean(x)) / np.std(x)\n",
    "    y_su = (y - np.mean(y)) / np.std(y)\n",
    "    return np.mean(x_su * y_su)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece4246a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "correlation(df['departure_hour'], df['minutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc2519",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Symmetric!\n",
    "correlation(df['minutes'], df['departure_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e70dba",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Doesn't change if we multiply x or y by constants!\n",
    "correlation(df['departure_hour'] * 1000, df['minutes'] * 545)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff2c28",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DataFrames have a built-in correlation method.\n",
    "df[['departure_hour', 'minutes']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9f0a0",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# numpy has a built-in corrcoef method.\n",
    "np.corrcoef(df['departure_hour'], df['minutes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce947de4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implementing $w_0^*$ and $w_1^*$, Again\n",
    "\n",
    "---\n",
    "\n",
    "Recall, the formulas for the optimal intercept and slope are:\n",
    "\n",
    "$$w_1^* = r \\frac{\\sigma_y}{\\sigma_x}$$\n",
    "\n",
    "$$w_0^* = \\bar{y} - w_1^* \\bar{x}$$\n",
    "\n",
    "Let's define two new functions, `slope_again` and `intercept_again`, which use these slightly updated formulas. (Really, only the formula for $w_1^*$ has changed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d4739",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def slope_again(x, y):\n",
    "    return correlation(x, y) * np.std(y) / np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aad079",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def intercept_again(x, y):\n",
    "    return y.mean() - slope_again(x, y) * x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e3d780",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w1_star_again = slope_again(df['departure_hour'], df['minutes'])\n",
    "w1_star_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6ff51",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w0_star_again = intercept_again(df['departure_hour'], df['minutes'])\n",
    "w0_star_again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5dca63",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We get the same optimal intercept and slope as before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa38f3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# From before:\n",
    "(w1_star, w0_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247d885f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now:\n",
    "(w1_star_again, w0_star_again)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b03dc1",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implementing $w_0^*$ and $w_1^*$ using `sklearn`\n",
    "\n",
    "---\n",
    "\n",
    "In practice, you wouldn't manually implement formulas for $w_0^*$ and $w_1^*$. Instead, you'd use a pre-built implementation.\n",
    "\n",
    "The Python package we'll use for machine learning is `sklearn`. We'll start seeing it more in lectures next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c493e5",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d483e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To build a linear regression model that we can use for prediction, we first need to instantiate a `LinearRegression` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980afcb",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4d15a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then, we need to `fit` the model by telling it what our $x$'s and $y$'s are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548d6b8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.fit(X=df[['departure_hour']], y=df['minutes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca9419",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once the model is fit, we can look at its `intercept_` and `coef_` attributes to see $w_0^*$ and $w_1^*$, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb6193",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0fce8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb04d3ca",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "These are **exactly the same** as we found with our manual calculations! This means that `sklearn` is doing the same three step modeling process that we outlined in lecture.\n",
    "\n",
    "Now that `model` is fit, we can use it for making predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f7f9c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We'll discuss this warning more in coming lectures.\n",
    "model.predict([[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc04a3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Using our hand-build predict_commute function from earlier in the lecture:\n",
    "predict_commute(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aaf7a9",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Aside: Pitfalls of Correlation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef48a57",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "anscombe = pd.read_csv('data/anscombe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe593fa",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "for i, n in enumerate(['I', 'II', 'III', 'IV']):\n",
    "    rows = anscombe[anscombe.get('dataset') == n]\n",
    "    x = rows['x']\n",
    "    y = rows['y']\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.scatter(x, y, label=f'Dataset {n}', alpha=0.65, s=65)\n",
    "    plt.title(f'Dataset {n}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c3bdf",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What do all four of these datasets have in common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2850f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i, n in enumerate(['I', 'II', 'III', 'IV']):\n",
    "    rows = anscombe[anscombe.get('dataset') == n]\n",
    "    x = rows['x']\n",
    "    y = rows['y']\n",
    "    r = correlation(x, y)\n",
    "    outstr = f'''\n",
    "    <b>Dataset {n}</b><br>\n",
    "    $\\\\bar x$: {np.round(np.mean(x), 2)}<br>\n",
    "    $\\\\bar y$: {np.round(np.mean(y), 2)}<br>\n",
    "    $\\\\sigma_x$: {np.round(np.std(x), 2)}<br>\n",
    "    $\\\\sigma_y$: {np.round(np.std(y), 2)}<br>\n",
    "    $r$: {np.round(r, 2)}\n",
    "    '''\n",
    "    display(HTML(outstr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce079351",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "They all share the exact same mean and standard deviation of $x$ and $y$, and the same correlation coefficient $r$! This means they all have the same best linear hypothesis function, in the sense of minimizing squared loss.\n",
    "\n",
    "However, that linear hypothesis function **looks** better for some datasets than it does for others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4733a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "for i, n in enumerate(['I', 'II', 'III', 'IV']):\n",
    "    rows = anscombe[anscombe.get('dataset') == n]\n",
    "    x = rows['x']\n",
    "    y = rows['y']\n",
    "    w0_ans = intercept(x, y)\n",
    "    w1_ans = slope(x, y)\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.scatter(x, y, label=f'Dataset {n}', alpha=0.65, s=65)\n",
    "    plt.plot(x, w0_ans + w1_ans * x, color='red');\n",
    "    plt.title(f'Dataset {n}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eed2577",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Moral of the story â€“ visualize your data before trying to fit a prediction rule!\n",
    "\n",
    "Another example of this phenomenon is the [Datasaurus Dozen ðŸ¦•](https://www.autodesk.com/research/publications/same-stats-different-graphs)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
