{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61132ac",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from lec_utils import *\n",
    "def sample_from_pop(n=100):\n",
    "    x = np.linspace(-2, 3, n)\n",
    "    y = x ** 3 + (np.random.normal(0, 3, size=n))\n",
    "    return pd.DataFrame({'x': x, 'y': y})\n",
    "sample_1 = sample_from_pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe75a0d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "#### Lecture 18\n",
    "\n",
    "# Feature Engineering, Continued\n",
    "\n",
    "### EECS 398-003: Practical Data Science, Fall 2024\n",
    "\n",
    "<small><a style=\"text-decoration: none\" href=\"https://practicaldsc.org\">practicaldsc.org</a> ‚Ä¢ <a style=\"text-decoration: none\" href=\"https://github.com/practicaldsc/fa24\">github.com/practicaldsc/fa24</a></small>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<script type=\"text/x-mathjax-config\">\n",
    "  MathJax.Hub.Config({\n",
    "    TeX: {\n",
    "      extensions: [\"color.js\"],\n",
    "      packages: {\"[+]\": [\"color\"]},\n",
    "    }\n",
    "  });\n",
    "  </script>\n",
    "  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b5e3e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements üì£\n",
    "\n",
    "- Homework 8 is due on **Friday** (not today!).\n",
    "- Homework 7 solutions are available at [**#259 on Ed**](https://edstem.org/us/courses/61012/discussion/5597496).\n",
    "- Check out the new [**FAQs page on the course website**](https://practicaldsc.org/faqs).<br><small>It has answers to frequently-asked theoretical questions.</small>\n",
    "- The IA application is out for next semester and is due on **Monday**! See [**#238 on Ed**](https://edstem.org/us/courses/61012/discussion/5563220) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940921c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Come say hi next Thursday!\n",
    "\n",
    "A few other professors and I are hosting a faculty-student panel, where you can learn more about our career (and personal) paths. Come say hi ‚Äì there will be pizza üçï!\n",
    "\n",
    "<center><img src=\"imgs/CSE Panel 11_7.png\" width=400></center>\n",
    "\n",
    "[**RSVP here**](https://docs.google.com/forms/d/e/1FAIpQLSchVg5byJC5cHJrUit8_e8d_Nb8NGEHk_vPKRWR3BBcnsq2gw/viewform)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d4edf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Recap: Multiple linear regression and feature engineering.\n",
    "- Numerical-to-numerical transformations.\n",
    "- The modeling recipe, revisited.\n",
    "- `OneHotEncoder` and multicollinearity.\n",
    "- `StandardScaler` and standardized regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c923a7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938abd69",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap: Multiple linear regression and feature engineering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7f86e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The general problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c7e1b3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  We have $n$ data points, $\\left({ \\vec x_1}, {y_1}\\right), \\left({ \\vec x_2}, {y_2}\\right),  \\ldots, \\left({ \\vec x_n}, {y_n}\\right)$,\n",
    "where each $ \\vec x_i$ is a feature vector of $d$ features:\n",
    "$${\\vec{x_i}} = \\begin{bmatrix} \n",
    "{x^{(1)}_i} \\\\ {x^{(2)}_i} \\\\ \\vdots \\\\ {x^{(d)}_i}\n",
    "\\end{bmatrix}$$\t   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20882bca",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  We want to find a good linear hypothesis function:\n",
    "$$\\begin{align*}\n",
    "                H({ \\vec x}) &= w_0 + w_1 { x^{(1)}} + w_2 { x^{(2)}} + \\ldots + w_d { x^{(d)}}\\\\\n",
    "                               &=    \\vec w \\cdot \\text{Aug}({ \\vec x})\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e4abf7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The general solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b1dd8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Define the **design matrix** $ X \\in \\mathbb{R}^{n \\times (d + 1)}$ and **observation vector** $ \\vec y \\in \\mathbb{R}^n$:\n",
    "\n",
    "$${ X=  \\begin{bmatrix}  \n",
    "{1} & { x^{(1)}_1} & { x^{(2)}_1} & \\dots & { x^{(d)}_1} \\\\\\\\\n",
    "{ 1} & { x^{(1)}_2} & { x^{(2)}_2} & \\dots & { x^{(d)}_2} \\\\\\\\\n",
    "\\vdots & \\vdots & \\vdots  &  & \\vdots \\\\\\\\\n",
    "{ 1} & { x^{(1)}_n} & { x^{(2)}_n} & \\dots & { x^{(d)}_n}\n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "       \\text{Aug}({\\vec{x_1}})^T \\\\\\\\\n",
    "       \\text{Aug}({\\vec{x_2}})^T \\\\\\\\\n",
    "       \\vdots \\\\\\\\\n",
    "       \\text{Aug}({\\vec{x_n}})^T\n",
    "   \\end{bmatrix}} \\qquad { \\vec y = \\begin{bmatrix} { y_1} \\\\ { y_2} \\\\ \\vdots \\\\ { y_n} \\end{bmatrix}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4458cc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Then, solve the **normal equations** to find the optimal parameter vector, $\\vec{w}^*$:\n",
    "\n",
    "    $${ X^TX} \\vec{w}^* = { X^T} { \\vec y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b25a67c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The goal of feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2a616",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Feature engineering** is the act of finding **transformations** that transform data into effective **quantitative variables**.<br><small>Put simply: feature engineering is creating new features using existing features.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6fdf98",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example**: One hot encoding.\n",
    "\n",
    "<center><img src=\"imgs/one-hot.png\" width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4ca687",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example**: Numerical-to-numerical transformations.\n",
    "\n",
    "<center><img src=\"imgs/quant-scale.png\" width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081ea8a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numerical-to-numerical transformations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3fc51",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1bc920",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linearization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca37a8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The [Tukey Mosteller Bulge Diagram](https://sites.stat.washington.edu/pds/stat423/Documents/LectureNotes/notes.423.ch4.pdf) helps us pick which **numerical-to-numerical** transformations to apply to data in order to **linearize** it.<br><small>Alternative interpretation: it helps us determine which features to create.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e95c7f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/bulge.png\" width=30%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c758c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Why**? We're working with linear models. The more linear our data looks in terms of its features, the better we'll able to model the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c070f9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc0fc1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Last class, we engineered a new feature by taking the $\\log$ of an existing feature; this is a **numerical-to-numerical** transformation.<br><small>This allowed us to create a _curve_ of best fit.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb16e518",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Consider the dataset below.<br><small>`sample_1` is defined at the top of this notebook.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80222f4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "px.scatter(sample_1, x='x', y='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b1fbd2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A simple linear regression line isn't sufficient enough to model the relationship between the two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b656591",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cff157",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The scatter plot appears to roughly resemble a degree 3 (cubic) polynomial, so let's try and fit a degree 3 polynomial. This will involve creating a design matrix with quadratic and cubic features.\n",
    "\n",
    "$$H(x) = w_0 + w_1x + w_2x^2 + w_3x^3$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e0d13",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = sample_1[['x']].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ea041",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Note that X itself is not the design matrix;\n",
    "# sklearn's LinearRegression object will create the needed design matrix\n",
    "# by adding a column of 1s to the start of X.\n",
    "X['x^2'] = X['x'] ** 2\n",
    "X['x^3'] = X['x'] ** 3\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b1b51",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now, let's fit a `LinearRegression` model from `sklearn` and look at the resulting predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9699c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e162b55",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X=X, y=sample_1['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c3191",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d73712",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(sample_1, x='x', y='y')\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=X['x'],\n",
    "    y=model.predict(X),\n",
    "    mode='lines',\n",
    "    line=dict(width=5),\n",
    "    name='Degree 3 Polynomial of Best Fit'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6c18f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The orange curve above is of the form:\n",
    "\n",
    "$$H^*(x) = -0.38 - 0.49x + 0.12x^2 + 1.05x^3$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c2c483",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc5c3c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c11148d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- While the curve is non-linear, it is **linear in the parameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf25323e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\" markdown=\"1\">\n",
    "\n",
    "#### Reference Slide\n",
    "\n",
    "### Example: Amdahl's Law"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1502aa76",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-  Amdahl's Law relates the runtime of a program on $p$ processors to the time to do the sequential and nonsequential parts on one processor.\t\n",
    "$$\\displaystyle H(p) = t_\\text{S} + \\frac{t_\\text{NS}}{p}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6392a83d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Collect data by timing a program with varying numbers of processors:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Processors | Time (Hours) |\n",
    "| --- | --- |\n",
    "| 1 | 8 |\n",
    "| 2 | 4 |\n",
    "| 4 | 3 |\n",
    "\n",
    "</center>\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d4672",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- To find $w_0^*$ and $w_1^*$ in the hypothesis function $H(x) = w_0 + w_1 \\cdot \\frac{1}{x}$, we need to create an appropriate design matrix:\n",
    "\n",
    "$$X = \\begin{bmatrix} 1 & \\frac{1}{1} \\\\ 1 & \\frac{1}{2} \\\\ 1 & \\frac{1}{4} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64f150",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Then, the problem reduces to finding the parameter vector, $\\vec{w}^*$, that solves the normal equations, $(X^TX)^{-1}X^T \\vec{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527758b9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "\n",
    "Which hypothesis function is **not** linear in the parameters?\n",
    "\n",
    "- A. $H(\\vec{x}) = w_1 (x^{(1)} x^{(2)}) + \\frac{w_2}{x^{(1)}} \\sin \\left( x^{(2)} \\right)$\n",
    "- B. $H(\\vec{x}) = 2^{w_1} x^{(1)}$\n",
    "- C. $H(\\vec{x}) = \\vec{w} \\cdot \\text{Aug}(\\vec{x})$\n",
    "- D. $H(\\vec{x}) = w_1 \\cos (x^{(1)}) + w_2 2^{x^{(2)} \\log x^{(3)}}$\n",
    "- E. More than one of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5222f874",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do we fit hypothesis functions that aren't linear in the parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390bde0a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Suppose we want to fit the hypothesis function:\n",
    "\n",
    "$$H(x) = w_0 e^{w_1 x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a889a88",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is **not** linear in terms of $w_0$ and $w_1$, so our results for linear regression don't apply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160c778",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  **Possible solution**: Try to transform the above equation so that it **is** linear in some other parameters, by applying an operation to both sides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456883d9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cebaf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$$H(x) = w_0 e^{w_1 x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adce492",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Suppose we take the $\\log$ of both sides of the equation.\n",
    "\n",
    "$$\\log H(x) = \\log (w_0 e^{w_1x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23203e64",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Then, using properties of logarithms, we have:\n",
    "\n",
    "$$\\log H(x) = \\underbrace{\\log(w_0)}_{\\text{this is just a constant!}} + w_1 x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62afc0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- **Solution**: Create a new hypothesis function, $T(x)$, with parameters $b_0$ and $b_1$, where $T(x) = b_0 + b_1 x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb601f1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-  This hypothesis function is related to $H(x)$ by the relationship $T(x) = \\log H(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a66b45",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-  $\\vec{b}$ is related to $\\vec{w}$ by $b_0 = \\log w_0$ and $b_1 = w_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb69a91e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-  Our new observation vector, $\\vec{z}$, is $\\begin{bmatrix} \\log y_1 \\\\ \\log y_2 \\\\ ... \\\\ \\log y_n \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744315a2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-  $T(x) = b_0 + b_1x$ is linear in its parameters, $b_0$ and $b_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5222028",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-  Use the solution to the normal equations to find $\\vec{b}^*$, and the relationship between $\\vec{b}$ and $\\vec{w}$ to find $\\vec{w}^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3217e74f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The modeling recipe, revisited\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdfdf2f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The original modeling recipe, from Lecture 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af828de1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Choose a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb66302",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Choose a loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c282fa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Minimize average loss to find optimal model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb339b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The updated modeling recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446a31e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "0. Create, or engineer, features to best reflect the \"meaning\" behind data.<br><small>Recently, we've done this with one hot encoding and numerical-to-numerical transformations.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274c3a6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Choose a model.<br><small>Recently, we've used the simple/multiple linear regression model.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35819263",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Choose a loss function.<br><small>Recently, we've mostly used squared loss.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5998bd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Minimize average loss (empirical risk) to find optimal model parameters, $\\vec{w}^*$.<br><small>Originally, we had to use calculus or linear algebra to minimize empirical risk, but more recently we've just used `model.fit`. This step is also called **fitting the model to the data**.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e640906",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. Evaluate the performance of the model in relation to other models, using MSE or $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eab5950",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **We can do all of the above directly in `sklearn`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc06b6c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/image_0.png\" width=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2daf8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `preprocessing` and `linear_model`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f19eba",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For the **feature engineering** step of the modeling pipeline, we will use `sklearn`'s [`preprocessing`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module.\n",
    "\n",
    "<center><img src=\"imgs/feature_part.png\" width=\"30%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1924257",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For the **model creation** step of the modeling pipeline, we will use `sklearn`'s [`linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) module, as we've already seen. `linear_model.LinearRegression` is an example of an **estimator** class.\n",
    "\n",
    "<center><img src=\"imgs/model_part.png\" width=\"36%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f0c14",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformer classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1e2ed",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Transformers** take in \"raw\" data and output \"processed\" data. They are used for **creating features**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c7bb6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Transformers, like most relevant features of `sklearn`, are **classes**, not functions, meaning you need to instantiate them and call their methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aa3e50",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Today, we'll introduce two transformer classes. We'll look at how to write code to use each one, but also discuss some of the underlying statistical nuances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ac4d8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Next class, we'll see how to chain transformers and estimators together into larger **Pipelines**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d903230b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `OneHotEncoder` and multicollinearity\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f321a63",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Commute times üöó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d043aa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For this first example, we'll continue working with our commute times dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a22c037",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/commute-times.csv')\n",
    "df['day_of_month'] = pd.to_datetime(df['date']).dt.day\n",
    "df['month'] = pd.to_datetime(df['date']).dt.month_name()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e3fec1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We'll focus specifically on the `'day'` and `'month'` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ab0c8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df[['day', 'month']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114ee799",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `OneHotEncoder`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97074b99",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Last class, we had to manually one hot encode the `'day'` column. Let's figure out how to one hot encode it automatically, along with the new `'month'` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caead59",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df[['day', 'month']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43987338",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- First, we need to import the relevant class from `sklearn.preprocessing`.<br><small>It's best practice to import just the relevant classes you need from `sklearn`.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59793c5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2c1f4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Like an estimator, we need to instantiate **and fit** our `OneHotEncoder` instsance before it can transform anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a7345",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c12ba4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Error!\n",
    "ohe.transform(df[['day', 'month']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523b3b4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Need to fit first.\n",
    "ohe.fit(df[['day', 'month']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e426360",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Once we've fit, when we use the `transform` method, we get a result we might not expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03007291",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ohe.transform(df[['day', 'month']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6476ed",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since the resulting matrix is **sparse** ‚Äì most of its elements are 0 ‚Äì `sklearn` uses a more efficient representation than a regular `numpy` array. We can convert to a regular (dense) array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac639bd3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ohe.transform(df[['day', 'month']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ceda9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The column names from `df[['day', 'month']]` don't appear in the output above. We can use the `get_feature_names_out` method on `ohe` to access the names and order of the one hot encoded columns, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff638e0",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe5d5b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(ohe.transform(df[['day', 'month']]).toarray(), \n",
    "             columns=ohe.get_feature_names_out()) # If we need a DataFrame back, for some reason."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bfd923",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Usually, we won't perform all of these intermediate steps, since the `OneHotEncoder` will be part of a larger **Pipeline**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6319e1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Heights and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3f2ea5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We now know how to use `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5d5d5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To illustrate a mathematical issue involving one hot encoding, let's load in another dataset, this time containing the weights and heights of 25,000 18 year olds, taken from [here](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_020108_HeightsWeights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc379430",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "people = pd.read_csv('data/heights-weights.csv').drop(columns=['Index'])\n",
    "people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c20675",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "people.plot(kind='scatter', x='Height (Inches)', y='Weight (Pounds)', \n",
    "            title='Weight vs. Height for 25,000 18 Year Olds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a755a7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivating example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdfaca6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we fit a simple linear regression model that uses **height in inches** to predict **weight in pounds**.\n",
    "\n",
    "$$\\text{predicted weight (pounds)} = w_0 + w_1 \\cdot \\text{height (inches)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa94165",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = people[['Height (Inches)']]\n",
    "y = people['Weight (Pounds)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab62f86",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "people_one_feat = LinearRegression()\n",
    "people_one_feat.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f35ea1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $w_0^*$ and $w_1^*$ are shown below, along with the model's MSE on the data we used to train it.<br><small>We call this the model's **training MSE**.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e090b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "people_one_feat.intercept_, people_one_feat.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b71e0c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y, people_one_feat.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34448d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An added feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e7e980",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now, suppose we fit another regression model, that uses **height in inches** AND **height in centimeters** to predict weight.\n",
    "\n",
    "$$\\text{predicted weight (pounds)} = w_0 + w_1 \\cdot \\text{height (inches)} + w_2 \\cdot \\text{height (cm)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdae3f4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "people['Height (cm)'] = people['Height (Inches)'] * 2.54 # 1 inch = 2.54 cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e0f6d1",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X2 = people[['Height (Inches)', 'Height (cm)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c2e5cd",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "people_two_feat = LinearRegression()\n",
    "people_two_feat.fit(X2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b105d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What are $w_0^*$, $w_1^*$, $w_2^*$, and the model's MSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80507c3a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "people_two_feat.intercept_, people_two_feat.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f224f70",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y, people_two_feat.predict(X2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e4d46",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Observation**: The intercept is the same as before (roughly -82.57), as is the MSE. However, the coefficients on `'Height (Inches)'` and `'Height (cm)'` are massive in size!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbd6b68",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It should be unsurprising that the MSE is the same, because the span of the design matrix is the same. So, the best predictions should be the same, too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0040f94",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But what's going on with the coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db89f7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Redundant features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53351c0d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's use simpler numbers for illustration. Suppose in the first model, $w_0^* = -80$ and $w_1^* = 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a50f4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\\text{predicted weight (pounds)} = -80 + 3 \\cdot \\text{height (inches)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715202a2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the second model, we have:\n",
    "\n",
    "$$\\begin{align*}\\text{predicted weight (pounds)} &= w_0^* + w_1^* \\cdot \\text{height (inches)} + w_2^* \\cdot \\text{height (cm)} \\\\ &= w_0^* + w_1^* \\cdot \\text{height (inches)} + w_2^* \\cdot \\big( 2.54^* \\cdot \\text{height (inches)} \\big) \\\\ &= w_0^* + \\left(w_1^* + 2.54 \\cdot w_2^* \\right) \\cdot \\text{height (inches)} \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c044b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the first model, we already found the \"best\" intercept ($-80$) and slope ($3$) in a linear model that uses height in inches to predict weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71253db9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **So, as long as $w_1^* + 2.54 \\cdot w_2^* = 3$ in the second model, the second model's predictions will be the same as the first, and hence they will also minimize MSE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398332f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Infinitely many parameter choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c8c155",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Issue**: There are an infinite number of $w_1^*$ and $w_2^*$ that satisfy $w_1^* + 2.54 \\cdot w_2^* = 3$!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97abbf5c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{predicted weight} = -80 - 10 \\cdot \\text{height (inches)} + \\frac{13}{2.54} \\cdot \\text{height (cm)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8ee5e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{predicted weight} = -80 + 10 \\cdot \\text{height (inches)} - \\frac{7}{2.54} \\cdot \\text{height (cm)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ee5fc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Both hypothesis functions look very different, but actually make the same predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce441f24",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `model.coef_` could return either set of coefficients, or any other of the infinitely many options. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ba9960",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But neither set of coefficients is **has any meaning!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342a1aa",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "(-80 - 10 * people.iloc[:, 0] + (13 / 2.54) * people.iloc[:, 2]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec0f1ae",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(-80 + 10 * people.iloc[:, 0] - (7 / 2.54) * people.iloc[:, 2]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218611e9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc856ca",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Multicollinearity occurs when features in a regression model are **highly correlated** with one another.<br><small>In other words, multicollinearity occurs when **a feature can be predicted using a linear combination of other features, fairly accurately**.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6749d202",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When multicollinearity is present in the features, the **coefficients in the model** are uninterpretable ‚Äì they have no meaning.<br><small>A \"slope\" represents \"the rate of change of $y$ with respect to a feature\", when all other features are held constant ‚Äì but if there's multicollinearity, you can't hold other features constant.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1887fc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Note: Multicollinearity doesn't impact a model's predictions!**\n",
    "    - It doesn't impact a model's ability to generalize to unseen data.\n",
    "    - If features are multicollinear in the data we've seen, they will probably be multicollinear in the data we haven't seen, drawn from the same distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dfda82",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solutions**:\n",
    "    - Manually remove highly correlated features.\n",
    "    - Use a dimensionality reduction technique (such as PCA) to automatically reduce dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a20e8c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One hot encoding and multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef825b6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **One hot encoding will result in multicollinearity unless you drop one of the one hot encoded features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edac726",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we have the following fitted model:<br><small>For illustration, assume `'weekend'` was originally a categorical feature with two possible values, `'Yes'` or `'No'`.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H(x) = 1 + 2 \\cdot (\\text{weekend==Yes}) - 2 \\cdot (\\text{weekend==No})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a457202a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is equivalent to:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H(x) = 10 - 7 \\cdot (\\text{weekend==Yes}) - 11 \\cdot (\\text{weekend==No})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352117b0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that for a particular row in the dataset, $\\text{weekend==Yes} + \\text{weekend==No}$ is always equal to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d5449",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This means that the columns of the design matrix, $X$, for this model is not linearly independent, since the column of all 1s can be written as a linear combination of the $\\text{weekend==Yes}$ and $\\text{weekend==No}$ columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed67438",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This means that the design matrix is not **full rank**, which means that $X^TX$ is **not invertible**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536b415",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This means that there are **infinitely many possible solutions $\\vec{w}^*$ to the normal equations, $(X^TX) \\vec{w} = X^T\\vec{y}$**!<br><small>That's a problem, because we don't know which of these infinitely many solutions `model.coef_` will find for us, and it's impossible to interpret the resulting coefficients, as we saw on the last slide.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406f80c6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solution**: Drop one of the one hot encoded columns. `OneHotEncoder` has an option to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c9334",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffb83f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `OneHotEncoder` returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64018c72",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's switch back to the commute times dataset, `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66822672",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df[['day', 'month']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6ab8c1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's try using `drop='first'` when instantiating a `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a171fb",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ohe_drop_one = OneHotEncoder(drop='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c0a7b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ohe_drop_one.fit(df[['day', 'month']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7f4942",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How many features did the resulting transformer create?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36dff20",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(ohe_drop_one.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f68861",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Where did this number come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dedb84",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['day'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24479841",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['month'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f4204",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67583313",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Multicollinearity is present in a linear model when one feature can be accurately predicted using one or more other features.<br><small>In other words, it is present when a feature is **redundant**.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348e06ce",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Multicollinearity doesn't pose an issue for prediction; it doesn't hinder a model's ability to generalize. Instead, it renders the **coefficients** of a linear model meaningless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44645692",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `StandardScaler` and standardized regression coefficients\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538ce68",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting sales üìà"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5396f0a7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To illustrate the next transformer class, we'll introduce a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4885d7",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('data/sales.csv')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f20ef",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For each of 26 stores, we have:\n",
    "    -  net sales, \n",
    "    -  square feet, \n",
    "    -  inventory,\n",
    "    -  advertising expenditure, \n",
    "    -  district size, and\n",
    "    -  number of competing stores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5b31f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our goal is to predict `'net_sales'` as a function of other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880f399b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4caccc4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3ead1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- No transformations are _needed_ to predict `'net_sales'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e2793",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales_model = LinearRegression()\n",
    "sales_model.fit(X=sales.iloc[:, 1:], y=sales.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09899397",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we're interested in learning **how** the various features impact `'net_sales'`, rather than just predicting `'net_sales'` for a new store. We'd then look at the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bab536",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2d7d2",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame().assign(\n",
    "    column=sales.columns[1:],\n",
    "    original_coef=sales_model.coef_,\n",
    ").set_index('column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d90553",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c5bf3f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47ad9d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Which features are most \"important\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fdaeb7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  The most important feature is **not necessarily** the feature with largest magnitude coefficient, because different features may be on different scales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a54d54",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose I fit two hypothesis functions:\n",
    "    - $H_1$ has store size measured in square feet.\n",
    "    - $H_2$ has store size measured in square meters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5238533a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Store size is just as important in both hypothesis functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73f152",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But 1 square meter $\\approx 10.76$ square feet, so the sizes in square meters will be 10.76x smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf1ec8c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So, the coefficient of store size in $H_2$ will be 10.76 times **larger** than the coefficient of store size in $H_1$.<br><small>Intuition: if the values themselves are smaller, you need to multiply them by bigger coefficients to get the same predictions!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0099128",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solution**: If you care about the interpretability of the resulting coefficients, **standardize** each feature before performing regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d9db2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074f96d9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Recall: to standardize a feature $x_1, x_2, ..., x_n$, we use the formula:\n",
    "    $$z(x_i) = \\frac{x_i - \\bar{x}}{\\sigma_x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6035a0c3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Example: 1, 7, 7, 9.\n",
    "    -  Mean: $\\frac{1 + 7 + 7 + 9}{4} = \\frac{24}{4} = 6$.\n",
    "    -  Standard deviation:\n",
    "\n",
    "    $$\\text{SD} = \\sqrt{\\frac{1}{4} \\left( (1-6)^2 + (7-6)^2 + (7-6)^2 + (9-6)^2 \\right)} = \\sqrt{\\frac{1}{4} \\cdot 36} = 3$$\n",
    "    -  Standardized data: \n",
    "\n",
    "    $$1 \\mapsto \\frac{1-6}{3} = \\boxed{-\\frac{5}{3}} \\qquad 7 \\mapsto \\frac{7-6}{3} = \\boxed{\\frac{1}{3}} \\qquad 7 \\mapsto \\boxed{\\frac{1}{3}} \\qquad 9 \\mapsto \\frac{9-6}{3} = \\boxed{1}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714fc59f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `StandardScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3411e563",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `StandardScaler` **standardizes** data using the mean and standard deviation of the data, as described on the previous slide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01894d0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Like `OneHotEncoder`, `StandardScaler` **requires some knowledge (mean and SD) of the dataset before transforming**, so we need to **`fit`** an `StandardScaler` transformer before we can use the `transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20d449",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff3d17",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This is like saying \"determine the mean and SD of each column in sales, \n",
    "# other than the 'net_sales' column\".\n",
    "stdscaler.fit(sales.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb63c22",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now, we can standardize any dataset, using the mean and standard deviation of the columns in `sales.iloc[:, 1:]`. Typical usage is to fit transformer on a sample and use that already-fit transformer to transform future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8230fe",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stdscaler.transform([[5, 300, 10, 15, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c30b6ea",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stdscaler.transform(sales.iloc[:, 1:].tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b0d07",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can peek under the hood and see what it computed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40696b4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stdscaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38431024",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stdscaler.var_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f739a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If needed, the `fit_transform` method will fit the transformer and then transform the data in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c7dc0",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3de19b0",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_scaler.fit_transform(sales.iloc[:, 1:].tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03aa216",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why are the values above different from the values in `stdscaler.transform(sales.iloc[:, 1:].tail(5))`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4216c5e0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpreting standardized regression coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c6e91",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now that we have a technique for standardizing the feature columns of `sales`, let's fit a new regression object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1336e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales_model_std = LinearRegression()\n",
    "sales_model_std.fit(X=stdscaler.transform(sales.iloc[:, 1:]),\n",
    "                    y=sales.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473d1b8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's now look at the resulting coefficients, and compare them to the coefficients before we standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe2be3e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame().assign(\n",
    "    column=sales.columns[1:],\n",
    "    original_coef=sales_model.coef_,\n",
    "    standardized_coef=sales_model_std.coef_\n",
    ").set_index('column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d345c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Did the performance of the resulting model change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e295faa",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(sales.iloc[:, 0],\n",
    "                   sales_model.predict(sales.iloc[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523d034",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(sales.iloc[:, 0],\n",
    "                   sales_model_std.predict(stdscaler.transform(sales.iloc[:, 1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83829de",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **No!**<br><small>The span of the design matrix did not change, so the predictions did not change. It's just the coefficients that changed.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf4104",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d23913e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  The result of standardizing each feature (separately!) is that the units of each feature are on the same scale.\n",
    "    -  There's no need to standardize the outcome (`'net_sales'` here), since it's not being compared to anything.\n",
    "    - Also, we can't standardize the column of all 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e447d2bf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Then, solve the normal equations. The resulting $w_0^*, w_1^*, \\ldots, w_d^*$ are called the **standardized regression coefficients**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e99a6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Standardized regression coefficients can be directly compared to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f31326",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we saw on the previous slide, standardizing each feature **does not** change the MSE of the resulting hypothesis function!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e41f77f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `StandardScaler` summary\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `stdscaler = StandardScaler()` | z-score the data (no parameters) |\n",
    "|Fit the transformer| `stdscaler.fit(X)` | Compute the mean and SD of `X`|\n",
    "|Transform data in a dataset | `feat = stdscaler.transform(X_new)` | z-score `X_new` with mean and SD of `X`|\n",
    "|Fit and transform| `stdscaler.fit_transform(X)` | Compute the mean and SD of `X`, then z-score `X`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a80cd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702030e6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Even though we have a `OneHotEncoder` transformer object, to actually use one hot encoding to make predictions, we need to:\n",
    "    - Manually instantiate a `OneHotEncoder` object, and then `fit` it.\n",
    "    - Create a new design matrix by taking the result of calling `transform` on the `OneHotEncoder` object and concatenating other relevant numerical columns.\n",
    "    - Manually instantiate a `LinearRegression` object, and then `fit` it using the result of the above step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb010d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we build more and more sophisticated models, it will be challenging to keep track of all of these individual steps ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a728c2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As such, we often build **Pipelines**."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
