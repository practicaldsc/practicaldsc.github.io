{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82837dd5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to get everything set up.\n",
    "from lec_utils import *\n",
    "import lec25_util as util\n",
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "from sklearn.model_selection import train_test_split\n",
    "diabetes = diabetes[(diabetes['Glucose'] > 0) & (diabetes['BMI'] > 0)]\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(diabetes[['Glucose', 'BMI']], diabetes['Outcome'], random_state=11)\n",
    ")\n",
    "from ipywidgets import interact\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d54ad1f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "#### Lecture 25\n",
    "\n",
    "# Decision Boundaries,  Multiclass Classification\n",
    "\n",
    "### EECS 398-003: Practical Data Science, Fall 2024\n",
    "\n",
    "<small><a style=\"text-decoration: none\" href=\"https://practicaldsc.org\">practicaldsc.org</a> • <a style=\"text-decoration: none\" href=\"https://github.com/practicaldsc/fa24\">github.com/practicaldsc/fa24</a></small>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5281090e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements 📣\n",
    "\n",
    "- Homework 10 is out, and is due on **Monday, December 2nd**.\n",
    "\n",
    "- Homework 11 will be out soon, and will be due on **Thursday, December 5th**.<br><small>It'll be fully autograded, with no hidden tests, and have just three questions.</small>\n",
    "\n",
    "- The Portfolio Homework is due on **Saturday, December 7th** – no slip days allowed!<br><small>We'll release checkpoint grades today; thanks for getting those in on time.</small>\n",
    "\n",
    "- Consider entering the Big Ten Data Viz Championship. Submissions are due on January 15th. Read more [**here**](https://it.umich.edu/community/data-viz-championship).<br><small>Help Michigan defend its title!</small>\n",
    "\n",
    "- Some suggested courses for next semester can be found in [**#306 on Ed**](https://edstem.org/us/courses/61012/discussion/5723634).<br><small>And please help spread the word about 398!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b2099",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Logistic regression.\n",
    "    - Recap.\n",
    "    - Choosing a threshold.\n",
    "    - Linear separability.\n",
    "- Multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a02a2ff",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question 🤔 (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b478ffc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap: Logistic regression\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7af65a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab297d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Logistic **regression** is a linear **classification** technique that builds upon linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca96e78",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It models **the probability of belonging to class 1, given a feature vector**:\n",
    "    \n",
    "$$P(y = 1 | \\vec{x}) = \\sigma (w_0 + w_1 x^{(1)} + w_2 x^{(2)} + ... + w_d x^{(d)}) = \\sigma\\left(\\vec{w} \\cdot \\text{Aug}(\\vec{x}) \\right)$$   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d41d1ff",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we train a logistic regression model to predict the probability a patient has diabetes ($y = 1$) given their `'Glucose'` and `'BMI'`. The optimal parameters we found were $\\vec{w}^* = \\begin{bmatrix} -8.1697 & 0.0394 & 0.0802 \\end{bmatrix}^T$. To predict probabilities, then, we use:\n",
    "\n",
    "$$P(y = 1 | \\text{Glucose}, \\text{BMI}) = \\sigma(−8.1697 + 0.0394 \\cdot \\text{Glucose} + 0.0802 \\cdot \\text{BMI})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd635909",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For instance, if someone has a `'Glucose'` level of 150 and `'BMI'` of 25, their predicted probability of diabetes is 43.67\\%:\n",
    "\n",
    "\\begin{align*}P(y = 1 | \\text{Glucose=150}, \\text{BMI=25}) &= \\sigma(-8.1697 + 0.0394 \\cdot 150 + 0.0802 \\cdot 25) \\\\ &= \\sigma(-0.2547) \\approx \\boxed{0.43667} \\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50799ca6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sigma = lambda t: 1 / (1 + np.e ** (-t))\n",
    "sigma(-0.2547)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8e9e50",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To find the optimal parameters $\\vec{w}^*$, we minimize mean **cross-entropy loss**:\n",
    "<br><small>There's no closed-form solution for $\\vec{w}^*$, so we use some numerical method (or, rather, `sklearn` does).</small>\n",
    "\n",
    "\\begin{align*}R_\\text{ce}(\\vec{w}) &= - \\frac{1}{n} \\sum_{i = 1}^n \\left( y_i \\log p_i + (1 - y_i) \\log (1 - p_i) \\right) \\\\ &= - \\frac{1}{n} \\sum_{i = 1}^n \\left[ y_i \\log \\left( \\sigma \\left(\\vec{w} \\cdot \\text{Aug}(\\vec{x}_i) \\right) \\right)  + (1 - y_i) \\log \\left(1 - \\sigma\\left(\\vec{w} \\cdot \\text{Aug}(\\vec{x}_i) \\right)\\right) \\right]\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e741b0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `LogisticRegression` in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f07ce6f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To illustrate, let's re-fit a model to predict diabetes from `'Glucose'` and `'BMI'` in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85958d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logistic_multiple = LogisticRegression()\n",
    "model_logistic_multiple.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f28dc1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- By default, the `predict` method of a fit `LogisticRegression` model predicts a **class**; it applies a threshold $T = 0.5$ to the predicted probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc83ecd",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_logistic_multiple.predict(pd.DataFrame([{\n",
    "    'Glucose': 150,\n",
    "    'BMI': 25,\n",
    "}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2163a8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can access the predicted **probabilities** using the `predict_proba` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a10476d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_logistic_multiple.predict_proba(pd.DataFrame([{\n",
    "    'Glucose': 150,\n",
    "    'BMI': 25,\n",
    "}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36116ae8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The decision boundary in the feature space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb9544",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- After choosing $T = 0.5$, what does the resulting <b><span style=\"color:purple\">decision boundary</span></b> look like, in a $d = 2$ dimensional plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073abc6",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_decision_boundary(model_logistic_multiple, X_train, y_train, title='Decision Boundary when Using Both Glucose and BMI \\n and T = 0.5 (the default)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc80ca",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that unlike the decision boundaries for $k$-Nearest Neighbors and decision trees, this decision boundary is **linear**. Specifically, it is the line:\n",
    "\n",
    "$$\\sigma(−8.1697 + 0.0394 \\cdot \\text{Glucose} + 0.0802 \\cdot \\text{BMI}) = 0.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f2763",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Important**: Since $\\sigma(0) = 0.5$, we can write the above as:\n",
    "\n",
    "$$-8.1697 + 0.0394 \\cdot \\text{Glucose} + 0.0802 \\cdot \\text{BMI} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba028647",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<h3>Question 🤔 (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Which expression describes the **odds ratio**, $$\\frac{P(y = 1 | \\vec{x})}{P(y = 0 | \\vec{x})}$$\n",
    "    \n",
    "in the logistic regression model?\n",
    "    \n",
    "- A. $\\vec{w} \\cdot \\text{Aug}(\\vec{x})$\n",
    "- B. $-\\vec{w} \\cdot \\text{Aug}(\\vec{x})$\n",
    "- C. $e^{\\vec{w} \\cdot \\text{Aug}(\\vec{x})}$\n",
    "- D. $\\sigma(\\vec{w} \\cdot \\text{Aug}(\\vec{x}))$\n",
    "- E. None of the above.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32cee12",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<h3>Question 🤔 (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Which expression describes $P(y = \\mathbf{0} | \\vec{x})$ in the logistic regression model?\n",
    "    \n",
    "- A. $\\sigma\\left(\\vec{w} \\cdot \\text{Aug}(\\vec{x}) \\right)$\n",
    "- B. $-\\sigma\\left(\\vec{w} \\cdot \\text{Aug}(\\vec{x}) \\right)$\n",
    "- C. $\\sigma\\left(- \\vec{w} \\cdot \\text{Aug}(\\vec{x}) \\right)$\n",
    "- D. $1 - \\log \\left( 1 + e^{\\vec{w} \\cdot \\text{Aug}(\\vec{x})} \\right)$\n",
    "- E. $1 + \\log \\left( 1 + e^{- \\vec{w} \\cdot \\text{Aug}(\\vec{x})} \\right)$\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d750b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing a threshold\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875eb09",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957fa99",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we've seen, in order to classify $\\vec{x}$ as either yes ($y = 1$) or no ($y = 0$), we apply a **threshold** $T$ to the predicted probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c44034",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/threshold.svg\" width=600><small>With a threshold of $T = 0.6$, a predicted probability of 0.68 is classified as <span style=\"color:blue\">yes diabetes (class 1)</span>,<br>and a predicted probability of 0.55 is classified as <span style=\"color:orange\">no diabetes (class 0)</span>.</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4add75",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- More generally, if we pick a threshold of $T$, then any feature vector $\\vec{x}$ such that:\n",
    "\n",
    "    $$\\sigma(\\vec{w}^* \\cdot \\text{Aug}(\\vec{x})) \\geq T$$ \n",
    "\n",
    "    is classified as class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b006fe84",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: How do we choose the \"right\" threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b8d80",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `sklearn`'s default threshold of $T = 0.5$ is **not** guaranteed to yield the highest **accuracy**!<br><small>Remember, to find $\\vec{w}^*$, we minimized mean cross-entropy loss (that is, we didn't \"maximize\" accuracy), and mean cross-entropy loss doesn't involve our threshold.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632eab02",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Choosing a custom threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c439c963",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we want to use a custom threshold, we'll need to implement the logic ourselves.\n",
    "\n",
    "<center><img src=\"imgs/threshold.svg\" width=300></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25162571",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_thresholded(X, T):\n",
    "    '''Calls model_logistic_multiple.predict_proba.\n",
    "       For each P(y = 1 | x), returns 1 if >= T and 0 if < T.'''\n",
    "    probs = model_logistic_multiple.predict_proba(X)[:, 1]\n",
    "    return (probs >= T).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e1f0f4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now, we can choose any threshold we'd like, and compute the accuracy of the resulting predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2756f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predict_thresholded([[150, 25]], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e201c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predict_thresholded([[150, 25]], 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0263a916",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predict_thresholded(X_train, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7efa27",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training accuracy for the threshold T = 0.4.\n",
    "(predict_thresholded(X_train, 0.4) == y_train).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f59eb45",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accuracy vs. threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7bfc02",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Accuracy is defined as:\n",
    "\n",
    "$$\\text{accuracy} = \\frac{\\text{# data points classified correctly}}{\\text{# data points}} = \\frac{TP + TN}{TP + FP + FN + TN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a08a70c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How does the model's **training** accuracy change as the threshold changes?<br><small>Note that we'd see a similar trend with test accuracy, too.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aa65a6",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.plot_vs_threshold(X_train, y_train, 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44ebe99",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The threshold with the best training accuracy (among the thresholds we tried) is $T = 0.485$, which has a training accuracy of 77.8\\%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2292e5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Remember that 65\\% of people in the dataset don't have diabetes, so we can achieve a 65\\% training accuracy just by always predicting \"no diabetes\"! This means that a good model's accuracy should be much higher than 65\\%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d5dc50",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c40afb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metrics for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb19292b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A few lectures ago, we introduced other metrics for measuring the quality of a binary classifier's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedece44",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{precision} = \\frac{TP}{\\text{# predicted positive}} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "<center><small>Here, a false positive ($FP$) is when we predict that someone has diabetes when they do not.</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c10e35",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{recall} = \\frac{TP}{\\text{# actually positive}} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "<center><small>Here, a false negative ($FN$) is when we predict that someone does not have diabetes, when they really do.</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2026d0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A binary classifier's **confusion matrix** displays its number of true positives ($TP$), false positives ($FP$), true negatives ($TN$), and false negatives ($FN$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec2ceab",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_confusion(X_train, y_train, T=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3811b30f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Remember, we're predicting whether or not patients have diabetes. **Which is worse: a false positive or a false negative?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6690f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Observe how the values in the confusion matrix change as the threshold changes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138bedd8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "interact(lambda T: util.show_confusion(X_train, y_train, T), T=(0, 1, 0.01));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d235f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision vs. threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32206fcd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Precision is defined as:\n",
    "\n",
    "    $$\\text{precision} = \\frac{TP}{\\text{# predicted positive}} = \\frac{TP}{TP + FP}$$\n",
    "    \n",
    "    Here, a false positive ($FP$) is when we predict that someone has diabetes when they do not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa770ea0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How does the model's training **precision** change as the threshold changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f06836",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.plot_vs_threshold(X_train, y_train, 'Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf144b3b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the \"bar\" is higher to predict 1, then we will have fewer positives in general, and thus fewer false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885eadc5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As the **threshold increases** ⬆️, the denominator in $\\text{precision} = \\frac{TP}{TP + FP}$ will decrease, and so **precision tends to increase** ⬆️.<br><small>There are some cases where a slightly higher threshold led to a slightly lower precision; why?</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e4e96c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall vs. threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda857b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Recall is defined as:\n",
    "\n",
    "    $$\\text{recall} = \\frac{TP}{\\text{# actually positive}} = \\frac{TP}{TP + FN}$$\n",
    "    \n",
    "    Here, a false negative ($FN$) is when we predict that someone does not have diabetes, when they really do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43088c27",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How does the model's training **recall** change as the threshold changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8288ee0",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.plot_vs_threshold(X_train, y_train, 'Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b519c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that the denominator in $\\text{recall} = \\frac{TP}{\\text{# actually positive}}$ is constant. As the **threshold increases** ⬆️:\n",
    "    - true positives get converted to false negatives, so\n",
    "    - the numerator of recall ($TP$) decreases, and so\n",
    "    - **recall decreases** ⬇️."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93406092",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision vs. recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221796a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can visualize how precision and recall vary **together**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d243a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.pr_curve(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce028db2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The curve above is called a **PR curve**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c277832e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Given the information above, what threshold would you choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99744905",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer**: The threshold whose point is closest to the **top right corner** of the plot above. <br><small>Why? The top right corner is where precision = 1 and recall = 1, and we want both to be high.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e54522",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4023a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A more popular variant of the PR curve is the **ROC curve**.<br><small>ROC stands for \"receiver operating characteristic.\"<br>See [**here**](https://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves) for a good discussion on the differences between PR curves and ROC curves.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b854e4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A ROC curve plots true positive rate (TPR) vs. false positive rate (FPR) for all possible thresholds, where:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf884bb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\underbrace{\\text{true positive rate (TPR)} = \\frac{TP}{\\text{# actually positive}} = \\frac{TP}{TP + FN} = \\text{recall}}_\\text{we want this to be close to 1!}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a68faf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\underbrace{\\text{false positive rate (FPR)} = \\frac{FP}{\\text{# actually negative}} = \\frac{FP}{FP + TN}}_\\text{we want this to be close to 0!}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b851d7f8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The ROC curve for our classifier looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e34771",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.draw_roc_curve(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212779cf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we care about TPR and FPR equally, the best threshold is the one whose point is closest to the **top left corner** in the plot above.<br><small>Why? The top left corner is where $TPR = 1$ and $FPR = 0$, and we want $TPR$ to be high and $FPR$ to be low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d6411",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A common metric for the quality of a binary classifier is the **area under curve (AUC)** for the ROC curve.<br><small>Larger values are better!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdc5615",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<h3>Question 🤔 (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "What questions do you have about thresholds and logistic regression?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7510e2e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear separability\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b23195",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f7fdf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we're using $d$ features as inputs to our classifier. Consider a visualization of the features in $d$-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44528b5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Example: $d = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8179f92e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_one_feature_plot_in_1D(X_train, y_train, thres=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cb346c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Example: $d = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26719878",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.make_two_feature_scatter(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebfdf2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that in both plots above, there are <span style=\"color:orange\">orange points</span> mixed in with the <span style=\"color:blue\">blue points</span>!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469e7ad3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear separability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abacb51c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A dataset is **linearly separable** if a line, plane, or hyperplane can be drawn in $d$-dimensional space that **perfectly separates** the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5770a2fd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Example: $d = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ba934",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.lin_sep_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82cffaa",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.non_lin_sep_1D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197de468",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Example: $d = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6aad6e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.lin_sep_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176e6c3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.non_lin_sep_2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26fe74d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Why is the dataset below **not** linearly separable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5017a1c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.bad_example_1D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b785d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear separability and decision boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf8bc7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- By definition, if a dataset is linearly separable, then there exists a **<span style=\"color:purple\">linear decision boundary</span>** that achieves 100\\% training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa38188",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.lin_sep_1D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc612bd2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Above, any value of $c$ in $(120, 150)$ would make the <b><span style=\"color:purple\">decision boundary</span></b> $$\\text{Glucose} = c$$\n",
    "achieve 100% training accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d4d59",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: How do we find this decision boundary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1adb74",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic regression and linear separability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e80dba",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Logistic regression, **without regularization**, **fails to converge** on linearly separable data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99bf029",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's re-draw the plot below, but with diabetes status drawn on the $y$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81a217",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.lin_sep_1D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8992abb2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why would the optimal $w_1^*$ below tend to $\\infty$?<br><small>See the annotated slides for more details.</small>\n",
    "\n",
    "$$P(y = 1 | \\text{Glucose}) = \\sigma(w_0 + w_1 \\cdot \\text{Glucose}) = \\frac{1}{1 + e^{-(w_0 + w_1 \\cdot \\text{Glucose})}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f101c34",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.lin_sep_1D_elevated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eed865",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To prevent this, logistic regression should **always** be regularized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd55de1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiclass classification\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe9409",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From binary to multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebece41",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In binary classification, there are only two possible classes, typically either 0 or 1.\n",
    "\n",
    "$$y_i \\in \\{0, 1\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b010d422",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In multiclass classification, there can be any finite number of classes, or **labels**. They need not be numbers, either.\n",
    "\n",
    "$$y_i \\in \\{ \\text{Adelie}, \\text{Chinstrap}, \\text{Gentoo} \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541253aa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Return of the penguins!\n",
    "\n",
    "<center><img src=\"imgs/lter_penguins.png\" width=60%>\n",
    "<i><a href=\"https://github.com/allisonhorst/palmerpenguins/blob/main/README.md\">Artwork by @allison_horst</a></i>\n",
    "\n",
    "</center>\n",
    "\n",
    "To illustrate multiclass classification, we'll revisit the Palmer Penguins dataset we saw earlier in the semester."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d37bc49",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ddad7a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset('penguins').dropna().reset_index(drop=True)\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105710db",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here, each row corresponds to a single penguin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b385f857",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are three `'species'` of penguin: Adelie, Chinstrap, and Gentoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545bf281",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "penguins['species'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ee1fc2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: What accuracy would the best \"constant\" classifier achieve on this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b62fc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18aef0b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Visually, it seems that the `'species'` are penguins are mostly separated based on their physical characteristics (`'bill_depth_mm'`, `'bill_length_mm'`, and `'body_mass_g'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57dc42",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.penguin_scatter_3d(penguins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bb1fa4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For simplicity, we'll work with just two features: `'bill_length_mm'` and `'body_mass_g'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802567c8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = util.penguin_scatter_2d(penguins)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d812cfac",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But first, a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de910852",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(penguins[['bill_length_mm', 'body_mass_g']], \n",
    "                                                    penguins['species'], \n",
    "                                                    random_state=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce7c78",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classifier 1: $k$-Nearest Neighbors 🏡🏠"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82a91b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Recall, suppose we're given a new penguin, $\\vec{x}_\\text{new} = \\begin{bmatrix} \\text{Bill Length}_\\text{new} \\\\ \\text{Body Mass}_\\text{new} \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24b44e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The $k$-Nearest Neighbors classifier ($k$-NN for short) classifies $\\vec{x}_\\text{new}$ by:\n",
    "    1. Finding the $k$ **closest points** in the training set to $\\vec{x}_\\text{new}$.\n",
    "    1. Predicting that $\\vec{x}_\\text{new}$ belongs to the **most common class** among those $k$ closest points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec5eae",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This approach doesn't depend on the number of classes, meaning that we can directly use a $k$-NN classifier for multiclass problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce021c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ce7f1e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `KNeighborsClassifier` in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5407e3d3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb50a0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's use the default of $k = 5$.<br><small>Of course, in practice, we _should_ cross-validate.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a482729",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b471f01",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are now three colors in the decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f0ff8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.penguin_decision_boundary(model_knn, X_train, y_train, title=\"Decision Boundary when k = 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253d6664",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classifier 2: Decision trees 🎄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db932fd8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Recall, suppose we're given a new penguin, $\\vec{x}_\\text{new} = \\begin{bmatrix} \\text{Bill Length}_\\text{new} \\\\ \\text{Body Mass}_\\text{new} \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab695bad",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The decision tree classifier classifies $\\vec{x}_\\text{new}$ by:\n",
    "    1. Asking a series of yes/no questions about $\\text{Bill Length}_\\text{new}$ and $\\text{Body Mass}_\\text{new}$, e.g.:\n",
    "    <br>\n",
    "    <center>Is $\\text{Bill Length}_\\text{new} \\leq 43.25$?<br>If so, is $\\text{Bill Length}_\\text{new} \\leq 41.55$?\n",
    "    <br>If not, is $\\text{Body Mass}_\\text{new} \\leq 4125$?<br>$\\vdots$</center>\n",
    "    2. Once it runs out of questions to ask, it predicts that $\\vec{x}_\\text{new}$ belongs to the **most common class** among training set points that had the same answers as $\\vec{x}_\\text{new}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc49095",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This approach also doesn't depend on the number of classes, meaning that we can directly use a decision tree classifier for multiclass problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde41c4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `DecisionTreeClassifier` in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef818e4d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c19a0f9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's fix `max_depth=3` so that we can visualize the resulting tree.<br><small>Again, in practice, we _should_ cross-validate.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e40bd",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(max_depth=3)\n",
    "model_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59143777",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that colors below don't directly match the colors in the scatter plot earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32f401",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(13, 5))\n",
    "plot_tree(model_tree, feature_names=X_train.columns, \n",
    "          class_names=['Adelie', 'Chinstrap', 'Gentoo'],\n",
    "          filled=True, fontsize=10, impurity=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9246ea8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.penguin_decision_boundary(model_tree, X_train, y_train, title=\"Decision Boundary for a Decision Tree\\nwith Depth = 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c16bc5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classifier 3: Logistic regression 📈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b253c391",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Logistic regression models **the probability of belonging to class 1, given a feature vector**:\n",
    "    \n",
    "$$P(y = 1 | \\vec{x}) = \\sigma (w_0 + w_1 x^{(1)} + w_2 x^{(2)} + ... + w_d x^{(d)}) = \\sigma\\left(\\vec{w} \\cdot \\text{Aug}(\\vec{x}) \\right)$$   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f9743a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our formulation of logistic regression only worked in the context of binary classification, i.e. when $y_i \\in \\{0, 1\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603f054",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Can we still use logistic regression somehow, now that we have three classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c45ef4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### \"One vs. rest\" logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f1d99",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One approach: Build **three separate logistic regression models**, each of which treat the problem as binary.\n",
    "    - One that predicts the probability of class Adelie, vs. not Adelie.<br><small>Here, $y=1$ means \"Adelie\" and $y=0$ means \"not Adelie\".</small>\n",
    "    - One that predicts the probability of class Chinstrap, vs. not-Chinstrap.\n",
    "    - One that predicts the probability of class Gentoo, vs. not-Gentoo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31b4edc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For a new penguin $\\vec{x}_\\text{new}$, compute all three probabilities, and predict the class with the highest predicted probability! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c3bb4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This technique is called **one-vs-rest**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349f9bc",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061ad03c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_logistic_ovr = OneVsRestClassifier(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52648be6",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_logistic_ovr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fec234",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.penguin_decision_boundary(model_logistic_ovr, X_train, y_train, title=\"Decision Boundary for a Decision Tree\\nwith Depth = 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee24e39a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that the resulting decision boundaries are still linear!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
